{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook works through the process of adding links from GeoKB items representing publications to contributors (authors, editors, etc.) that are also entities in the knowledge graph. This is built here as a secondary process run after a first pass where a subset of publication items were introduced from the USGS Publications Warehouse. It represents an iterative approach to building the knowledge graph which is likely how much of this work will play out over time. We might start with an initial representation for some type of entity containing properties we are using at the time, but then we might come back in and add additional information from the original or a related source to create new linkages and add further capability to the items.\n",
    "\n",
    "I worked here with a cache I'd made previously of USGS Pubs Warehouse records for the iSAID work. I need to revisit how that process works and particularly what I think is a new type of interface built on GraphQL for the PW that should dramatically improve interface efficiency over the REST API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from wbmaker import WikibaseConnection\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "geokb = WikibaseConnection('GEOKB_CLOUD')\n",
    "\n",
    "# Using a temporary cache of PW items from a database source for efficiency\n",
    "isaid = geokb.pg_cnxn(\n",
    "    db=\"isaid\",\n",
    "    db_user=os.environ[\"rds_username\"],\n",
    "    db_pass=os.environ[\"rds_password\"],\n",
    "    db_host=os.environ[\"rds_host\"],\n",
    "    db_port=os.environ[\"rds_port\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get PW cache and the pubs we will be building on from the GeoKB\n",
    "pw_cache = pd.read_sql_query(\n",
    "    \"\"\"\n",
    "        SELECT \"indexId\", contributors\n",
    "        FROM source_pw\n",
    "    \"\"\", \n",
    "    con=isaid\n",
    ")\n",
    "\n",
    "geokb_pw_pubs = geokb.url_sparql_query(\n",
    "    sparql_url=\"https://geokb.wikibase.cloud/query/sparql?query=PREFIX%20wd%3A%20%3Chttps%3A%2F%2Fgeokb.wikibase.cloud%2Fentity%2F%3E%0APREFIX%20wdt%3A%20%3Chttps%3A%2F%2Fgeokb.wikibase.cloud%2Fprop%2Fdirect%2F%3E%0A%0ASELECT%20%3Fitem%20%3Fpw_index_id%0AWHERE%20%7B%0A%20%20%3Fitem%20wdt%3AP1%2Fwdt%3AP2*%20wd%3AQ11%20.%0A%20%20%3Fitem%20wdt%3AP114%20%3Fpw_index_id%20.%0A%7D\",\n",
    "    output_format=\"dataframe\"\n",
    ")\n",
    "geokb_pw_pubs[\"qid\"] = geokb_pw_pubs[\"item\"].apply(lambda x: x.split(\"/\")[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put identifiers together so we can build out the structure we need and break out contributor types\n",
    "geokb_pubs_contributors = pd.merge(\n",
    "    left=geokb_pw_pubs[[\"qid\",\"pw_index_id\"]],\n",
    "    right=pw_cache.rename(columns={\"indexId\": \"pw_index_id\"}),\n",
    "    how=\"left\",\n",
    "    on=\"pw_index_id\"\n",
    ")\n",
    "\n",
    "geokb_pubs_contributors[\"contributors\"] = geokb_pubs_contributors[\"contributors\"].apply(json.loads)\n",
    "\n",
    "contributors_normalized = pd.json_normalize(geokb_pubs_contributors[\"contributors\"])\n",
    "geokb_pubs_contributors_combined = pd.concat([\n",
    "    geokb_pubs_contributors.drop(\"contributors\", axis=1),\n",
    "    contributors_normalized\n",
    "], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Break out each contributor type\n",
    "geokb_pw_authors = geokb_pubs_contributors_combined[geokb_pubs_contributors_combined[\"authors\"].notnull()][[\"qid\",\"authors\"]].reset_index(drop=True)\n",
    "geokb_pw_editors = geokb_pubs_contributors_combined[geokb_pubs_contributors_combined[\"editors\"].notnull()][[\"qid\",\"editors\"]].reset_index(drop=True)\n",
    "geokb_pw_compilers = geokb_pubs_contributors_combined[geokb_pubs_contributors_combined[\"compilers\"].notnull()][[\"qid\",\"compilers\"]].reset_index(drop=True)\n",
    "\n",
    "# Normalize the properties in the contributors structure for each contributor type\n",
    "geokb_pw_authors = geokb_pw_authors.explode(\"authors\").reset_index(drop=True)\n",
    "\n",
    "geokb_pw_author_props = pd.json_normalize(geokb_pw_authors[\"authors\"])\n",
    "geokb_pw_authors = pd.concat([\n",
    "    geokb_pw_authors.drop(\"authors\", axis=1),\n",
    "    geokb_pw_author_props\n",
    "], axis=1)\n",
    "\n",
    "geokb_pw_authors_identified = geokb_pw_authors[geokb_pw_authors.email.notnull() | geokb_pw_authors.orcid.notnull()][[\"qid\",\"email\",\"orcid\"]].reset_index(drop=True)\n",
    "geokb_pw_authors_identified[\"orcid\"] = geokb_pw_authors_identified[\"orcid\"].apply(lambda x: x.replace(\"https://orcid.org/\", \"\") if isinstance(x, str) else None)\n",
    "\n",
    "\n",
    "geokb_pw_editors = geokb_pw_editors.explode(\"editors\").reset_index(drop=True)\n",
    "\n",
    "geokb_pw_editor_props = pd.json_normalize(geokb_pw_editors[\"editors\"])\n",
    "geokb_pw_editors = pd.concat([\n",
    "    geokb_pw_editors.drop(\"editors\", axis=1),\n",
    "    geokb_pw_editor_props\n",
    "], axis=1)\n",
    "\n",
    "geokb_pw_editors_identified = geokb_pw_editors[geokb_pw_editors.email.notnull() | geokb_pw_editors.orcid.notnull()][[\"qid\",\"email\",\"orcid\"]].reset_index(drop=True)\n",
    "geokb_pw_editors_identified[\"orcid\"] = geokb_pw_editors_identified[\"orcid\"].apply(lambda x: x.replace(\"https://orcid.org/\", \"\") if isinstance(x, str) else None)\n",
    "\n",
    "\n",
    "geokb_pw_compilers = geokb_pw_compilers.explode(\"compilers\").reset_index(drop=True)\n",
    "\n",
    "geokb_pw_compiler_props = pd.json_normalize(geokb_pw_compilers[\"compilers\"])\n",
    "geokb_pw_compilers = pd.concat([\n",
    "    geokb_pw_compilers.drop(\"compilers\", axis=1),\n",
    "    geokb_pw_compiler_props\n",
    "], axis=1)\n",
    "\n",
    "geokb_pw_compilers_identified = geokb_pw_compilers[geokb_pw_compilers.email.notnull() | geokb_pw_compilers.orcid.notnull()][[\"qid\",\"email\",\"orcid\"]].reset_index(drop=True)\n",
    "geokb_pw_compilers_identified[\"orcid\"] = geokb_pw_compilers_identified[\"orcid\"].apply(lambda x: x.replace(\"https://orcid.org/\", \"\") if isinstance(x, str) else None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the ORCIDs and emails we have in the GeoKB source\n",
    "geokb_person_email = geokb.url_sparql_query(\n",
    "    sparql_url=\"https://geokb.wikibase.cloud/query/sparql?query=PREFIX%20wd%3A%20%3Chttps%3A%2F%2Fgeokb.wikibase.cloud%2Fentity%2F%3E%0APREFIX%20wdt%3A%20%3Chttps%3A%2F%2Fgeokb.wikibase.cloud%2Fprop%2Fdirect%2F%3E%0A%0ASELECT%20%3Fperson%20%3Femail%0AWHERE%20%7B%0A%20%20%3Fperson%20wdt%3AP1%20wd%3AQ3%20.%0A%20%20%3Fperson%20wdt%3AP109%20%3Femail%20.%0A%7D\",\n",
    "    output_format=\"dataframe\"\n",
    ")\n",
    "geokb_person_email[\"person_qid\"] = geokb_person_email[\"person\"].apply(lambda x: x.split(\"/\")[-1])\n",
    "geokb_person_email[\"email\"] = geokb_person_email[\"email\"].apply(lambda x: x.split(\":\")[-1])\n",
    "\n",
    "geokb_person_orcid = geokb.url_sparql_query(\n",
    "    sparql_url=\"https://geokb.wikibase.cloud/query/sparql?query=PREFIX%20wd%3A%20%3Chttps%3A%2F%2Fgeokb.wikibase.cloud%2Fentity%2F%3E%0APREFIX%20wdt%3A%20%3Chttps%3A%2F%2Fgeokb.wikibase.cloud%2Fprop%2Fdirect%2F%3E%0A%0ASELECT%20%3Fperson%20%3Forcid%0AWHERE%20%7B%0A%20%20%3Fperson%20wdt%3AP1%20wd%3AQ3%20.%0A%20%20%3Fperson%20wdt%3AP106%20%3Forcid%20.%0A%7D\",\n",
    "    output_format=\"dataframe\"\n",
    ")\n",
    "geokb_person_orcid[\"person_qid\"] = geokb_person_orcid[\"person\"].apply(lambda x: x.split(\"/\")[-1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine document and person identifiers for each contributor type for unique identifier (orcid or email) connections\n",
    "linked_authors_on_orcid = pd.merge(\n",
    "    left=geokb_pw_authors_identified[geokb_pw_authors_identified.orcid.notnull()][[\"qid\",\"orcid\"]],\n",
    "    right=geokb_person_orcid[[\"person_qid\",\"orcid\"]],\n",
    "    how=\"inner\",\n",
    "    on=\"orcid\"\n",
    ")\n",
    "\n",
    "linked_authors_on_email = pd.merge(\n",
    "    left=geokb_pw_authors_identified[geokb_pw_authors_identified.email.notnull()][[\"qid\",\"email\"]],\n",
    "    right=geokb_person_email[[\"person_qid\",\"email\"]],\n",
    "    how=\"inner\",\n",
    "    on=\"email\"\n",
    ")\n",
    "\n",
    "linked_authors = np.unique(\n",
    "    np.concatenate((\n",
    "        linked_authors_on_orcid[[\"qid\",\"person_qid\"]].to_records(index=False),\n",
    "        linked_authors_on_email[[\"qid\",\"person_qid\"]].to_records(index=False)\n",
    "    ))\n",
    ")\n",
    "\n",
    "df_linked_authors = pd.DataFrame.from_records(linked_authors)\n",
    "\n",
    "\n",
    "linked_editors_on_orcid = pd.merge(\n",
    "    left=geokb_pw_editors_identified[geokb_pw_editors_identified.orcid.notnull()][[\"qid\",\"orcid\"]],\n",
    "    right=geokb_person_orcid[[\"person_qid\",\"orcid\"]],\n",
    "    how=\"inner\",\n",
    "    on=\"orcid\"\n",
    ")\n",
    "\n",
    "linked_editors_on_email = pd.merge(\n",
    "    left=geokb_pw_editors_identified[geokb_pw_editors_identified.email.notnull()][[\"qid\",\"email\"]],\n",
    "    right=geokb_person_email[[\"person_qid\",\"email\"]],\n",
    "    how=\"inner\",\n",
    "    on=\"email\"\n",
    ")\n",
    "\n",
    "linked_editors = np.unique(\n",
    "    np.concatenate((\n",
    "        linked_editors_on_orcid[[\"qid\",\"person_qid\"]].to_records(index=False),\n",
    "        linked_editors_on_email[[\"qid\",\"person_qid\"]].to_records(index=False)\n",
    "    ))\n",
    ")\n",
    "\n",
    "df_linked_editors = pd.DataFrame.from_records(linked_editors)\n",
    "\n",
    "\n",
    "linked_compilers_on_orcid = pd.merge(\n",
    "    left=geokb_pw_compilers_identified[geokb_pw_compilers_identified.orcid.notnull()][[\"qid\",\"orcid\"]],\n",
    "    right=geokb_person_orcid[[\"person_qid\",\"orcid\"]],\n",
    "    how=\"inner\",\n",
    "    on=\"orcid\"\n",
    ")\n",
    "\n",
    "linked_compilers_on_email = pd.merge(\n",
    "    left=geokb_pw_compilers_identified[geokb_pw_compilers_identified.email.notnull()][[\"qid\",\"email\"]],\n",
    "    right=geokb_person_email[[\"person_qid\",\"email\"]],\n",
    "    how=\"inner\",\n",
    "    on=\"email\"\n",
    ")\n",
    "\n",
    "linked_compilers = np.unique(\n",
    "    np.concatenate((\n",
    "        linked_compilers_on_orcid[[\"qid\",\"person_qid\"]].to_records(index=False),\n",
    "        linked_compilers_on_email[[\"qid\",\"person_qid\"]].to_records(index=False)\n",
    "    ))\n",
    ")\n",
    "\n",
    "df_linked_compilers = pd.DataFrame.from_records(linked_compilers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the appropriate property identifier for each contributor type\n",
    "# Note: editor and compiler were just added and the indexing process in the Wikibase instance is still behind\n",
    "df_linked_authors[\"predicate\"] = geokb.prop_lookup[\"author\"]\n",
    "df_linked_editors[\"predicate\"] = \"P115\"\n",
    "df_linked_compilers[\"predicate\"] = \"P116\"\n",
    "\n",
    "df_linked_contributors = pd.concat([\n",
    "    df_linked_authors,\n",
    "    df_linked_editors,\n",
    "    df_linked_compilers\n",
    "])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point we have a structure we can work through to pull existing publication items and add links to their contribtors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q54967 ['Q50723']\n",
      "Q55021 ['Q46517', 'Q54742']\n",
      "Q55039 ['Q46517']\n",
      "Q55043 ['Q45644', 'Q46517', 'Q54742', 'Q54870']\n",
      "Q55044 ['Q46517', 'Q54742']\n",
      "Q55049 ['Q46830', 'Q48043', 'Q49590']\n",
      "Q55055 ['Q49216', 'Q50599']\n"
     ]
    }
   ],
   "source": [
    "refs = geokb.models.References()\n",
    "refs.add(\n",
    "    geokb.datatypes.Item(\n",
    "        prop_nr=geokb.prop_lookup[\"data source\"],\n",
    "        value=\"Q54915\"\n",
    "    )\n",
    ")\n",
    "\n",
    "# I already ran through authors here, so I'm filtering those out for this run\n",
    "df_linked_contributors = df_linked_contributors[df_linked_contributors.predicate != \"P102\"]\n",
    "\n",
    "for (pub_qid, contributor_pid), contributor_qids in df_linked_contributors.groupby([\"qid\",\"predicate\"])[\"person_qid\"].agg(list).items():\n",
    "    item = geokb.wbi.item.get(pub_qid)\n",
    "\n",
    "    contributor_claims = []\n",
    "    for qid in contributor_qids:\n",
    "        contributor_claims.append(\n",
    "            geokb.datatypes.Item(\n",
    "                prop_nr=contributor_pid,\n",
    "                value=qid,\n",
    "                references=refs\n",
    "            )\n",
    "        )\n",
    "    item.claims.add(contributor_claims)\n",
    "\n",
    "    response = item.write(\n",
    "        summary=\"Added linkable contributors to publication record\"\n",
    "    )\n",
    "    print(response.id, contributor_qids)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:isaid]",
   "language": "python",
   "name": "conda-env-isaid-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
