{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will be using place names all over the place in the GeoKB. These will often be in addition to geographic coordinate claims on items, providing simple name-based characterization useful in all kinds of searches and reporting. We may have bots that operate internally to the GeoKB, building from coordinates to introduce derived place name claims. Or they may come in from source material.\n",
    "\n",
    "Our GeoKB is likely not an authority for any place names, so we need to develop a series of bots to handle one-time and potentially periodic updating of place references. This notebook starts to build these out, and we may move to more purpose-built code for the bots in future.\n",
    "\n",
    "# Bot Operator\n",
    "\n",
    "Following the principle outlined in the README, there is a specific bot account for handling this process. Establishing foundational place name/geospatial references will be something we need to revisit routinely as we bring in additional data sources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import requests\n",
    "from zipfile import ZipFile\n",
    "from io import BytesIO\n",
    "import swifter\n",
    "import geopandas as gpd\n",
    "\n",
    "from utils import (\n",
    "    sparql_query,\n",
    "    query_by_item_label,\n",
    "    property_lookup\n",
    ")\n",
    "\n",
    "from wikibaseintegrator.wbi_config import config as wbi_config\n",
    "from wikibaseintegrator import WikibaseIntegrator, wbi_login, wbi_helpers\n",
    "from wikibaseintegrator.datatypes import Item, String, ExternalID, URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vist the README for information on these variables\n",
    "wbi_config['MEDIAWIKI_API_URL'] = os.environ['MEDIAWIKI_API_URL']\n",
    "wbi_config['SPARQL_ENDPOINT_URL'] = os.environ['SPARQL_ENDPOINT_URL']\n",
    "wbi_config['WIKIBASE_URL'] = os.environ['WIKIBASE_URL']\n",
    "\n",
    "# Use bot account for this specific task\n",
    "geokb_auth = wbi_login.Login(\n",
    "    user=os.environ['WB_BOT_GEO'], \n",
    "    password=os.environ['WB_PASS_GEO']\n",
    ")\n",
    "wbi = WikibaseIntegrator(login=geokb_auth)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Properties and Classes\n",
    "\n",
    "Working through places introduces new properties and classification items:\n",
    "\n",
    "* geographic region (aka place)\n",
    "    * Rather than try to be exhaustive on this, I stuck with a simple high level item (subclass of entity) for now. We can make this more complex in future if needed.\n",
    "* US State\n",
    "    * I debated this for some time but ended up using one of the same methods employed in Wikidata with this very specific classifier. Wikidata also uses a much broader classification scheme for \"administrative units\" of various kinds within some larger administrative unit. With this approach, we'll have the same thing with the need for Canadian Province, Mexican State, and other specific classifiers. In a lot of ways, I'd rather keep the semantics at a more general level, but for now, this is what may communicate best in our context.\n",
    "* ISO 3166-1 alpha-2 code, ISO 3166-2 code, FIPS 5-2 alpha code (US states), FIPS 5-2 numeric code (US state)\n",
    "    * Specific properties (ExternalID datatype) leveraged from Wikidata as identifiers we need in linking from other data sources\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'instance of': 'P1',\n",
       " 'subclass of': 'P2',\n",
       " 'reference item': 'P3',\n",
       " 'reference url': 'P4',\n",
       " 'reference statement': 'P5',\n",
       " 'coordinate location': 'P6',\n",
       " 'publication date': 'P7',\n",
       " 'subject matter': 'P8',\n",
       " 'ranking': 'P9',\n",
       " 'ISO 3166-1 alpha-2 code': 'P10',\n",
       " 'located in the administrative territorial entity': 'P11',\n",
       " 'ISO 3166-2 code': 'P12',\n",
       " 'FIPS 5-2 alpha code (US states)': 'P13',\n",
       " 'FIPS 5-2 numeric code (US states)': 'P14',\n",
       " 'corresponding wikidata property': 'P15',\n",
       " 'related wikidata item': 'P16',\n",
       " 'element symbol': 'P17',\n",
       " 'SEDAR Identifier': 'P18',\n",
       " 'MRDS commodity code': 'P19',\n",
       " 'USGS Thesaurus ID': 'P20'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "geokb_props = property_lookup()\n",
    "geokb_props"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Countries\n",
    "\n",
    "For our mineral assessment use cases, we need items in GeoKB for every country where we have something like a mineral occurrence record or a document dealing with a mineral prospect in that country. So, we may as well input every country in the world from some reasonable source. There are lots of places we could go for this, but the Wikidata source of country records is pretty robust with a massive slate of properties for many countries because they are in such heavy use within the global knowledgebase.\n",
    "\n",
    "Here, I run a query that pulls back just the essential bits we need right now:\n",
    "* country name (ignoring aliases for now)\n",
    "* country description\n",
    "* two-character ISO3166 country code\n",
    "\n",
    "We might need numeric codes at some point as well, but this is the minimum to start."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wd_country_query = \"\"\"\n",
    "SELECT ?country ?countryLabel ?countryDescription ?country_code WHERE {\n",
    "  SERVICE wikibase:label { bd:serviceParam wikibase:language \"[AUTO_LANGUAGE],en\". }\n",
    "  ?country wdt:P31 wd:Q6256.\n",
    "  OPTIONAL {\n",
    "  VALUES (?property) {\n",
    "    (wdt:P297)\n",
    "  }  \n",
    "  ?country ?property ?country_code.\n",
    "  }\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "wd_countries = sparql_query(\n",
    "    endpoint='https://query.wikidata.org/sparql',\n",
    "    query=wd_country_query,\n",
    "    output='dataframe'\n",
    ")\n",
    "wd_countries.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wd_countries[wd_countries.countryLabel.str.contains('United')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_label_id(label):\n",
    "    label_query = query_by_item_label(label=label, include_aliases=False)\n",
    "    geokb_results = wbi_helpers.execute_sparql_query(label_query)\n",
    "    if len(geokb_results[\"results\"][\"bindings\"]) == 1:\n",
    "        return geokb_results[\"results\"][\"bindings\"][0][\"item\"][\"value\"].split('/')[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_label_id('United States of America')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_item(label: str, description: str, aliases: list|str|None, claims: list|None):\n",
    "    item = wbi.item.new()\n",
    "\n",
    "    item.labels.set(language='en', value=label)\n",
    "    item.descriptions.set(language='en', value=description)\n",
    "    item.aliases.set(language='en', values=aliases)\n",
    "    item.claims.add(claims)\n",
    "\n",
    "    item.write()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "instance_of = 'P1'\n",
    "country_code_prop = 'P10'\n",
    "country_class = 'Q27'\n",
    "\n",
    "instance_of_country_claim = Item(\n",
    "    prop_nr=instance_of, \n",
    "    value=country_class\n",
    ")\n",
    "\n",
    "for index, row in wd_countries[wd_countries.country_code != 'ZA'].iterrows():\n",
    "    print(\"PROCESSING:\", row.countryLabel)\n",
    "    claims = [instance_of_country_claim]\n",
    "    if row.country_code:\n",
    "        country_code_claim = String(\n",
    "            prop_nr=country_code_prop,\n",
    "            value=row.country_code\n",
    "        )\n",
    "        claims.append(country_code_claim)\n",
    "\n",
    "    add_item(\n",
    "        label=row.countryLabel,\n",
    "        description=row.countryDescription,\n",
    "        aliases=row.country_code,\n",
    "        claims=claims\n",
    "    )\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sub-country Units\n",
    "\n",
    "We at least also need U.S. States and Territories and may need states/provinces from other countries as I know those show up in some of our data. We'll also probably want U.S. Counties. We'll introduce additional sub-country administrative units as they come up in our data sources, working through the same overall logic on identifying and processing reasonable reference sources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wd_us_states_query = \"\"\"\n",
    "SELECT DISTINCT ?state ?stateLabel ?stateDescription ?iso3166 ?fips_alpha ?fips_numeric WHERE {\n",
    "  SERVICE wikibase:label { bd:serviceParam wikibase:language \"[AUTO_LANGUAGE],en\". }\n",
    "  ?state wdt:P31 wd:Q35657.\n",
    "  OPTIONAL {\n",
    "  VALUES (?propertyISO3166) {\n",
    "    (wdt:P300)\n",
    "  }  \n",
    "  ?state ?propertyISO3166 ?iso3166.\n",
    "  VALUES (?propertyFipsNumeric) {\n",
    "    (wdt:P5087)\n",
    "  }  \n",
    "  ?state ?propertyFipsNumeric ?fips_numeric.\n",
    "  VALUES (?propertyFipsAlpha) {\n",
    "    (wdt:P5086)\n",
    "  }  \n",
    "  ?state ?propertyFipsAlpha ?fips_alpha.\n",
    "  }\n",
    "}\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "wd_us_states = sparql_query(\n",
    "    endpoint='https://query.wikidata.org/sparql',\n",
    "    query=wd_us_states_query,\n",
    "    output='dataframe'\n",
    ")\n",
    "wd_us_states.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reference_url = 'P4'\n",
    "us_state = 'Q229'\n",
    "is_located_in = 'P11'\n",
    "us = 'Q161'\n",
    "iso_3166_2 = 'P12'\n",
    "fips_alpha = 'P13'\n",
    "fips_numeric = 'P14'\n",
    "\n",
    "state_instance_of_claim = Item(\n",
    "    prop_nr=instance_of,\n",
    "    value=us_state\n",
    ")\n",
    "\n",
    "located_in_us_claim = Item(\n",
    "    prop_nr=is_located_in,\n",
    "    value=us\n",
    ")\n",
    "\n",
    "for index, row in wd_us_states.iterrows():\n",
    "    references = [URL(\n",
    "        prop_nr=reference_url,\n",
    "        value=row.state\n",
    "    )]\n",
    "\n",
    "    iso_3166_claim = ExternalID(\n",
    "        prop_nr=iso_3166_2,\n",
    "        value=row.iso3166,\n",
    "        references=references\n",
    "    )\n",
    "\n",
    "    fips_alpha_claim = ExternalID(\n",
    "        prop_nr=fips_alpha,\n",
    "        value=row.fips_alpha,\n",
    "        references=references\n",
    "    )\n",
    "\n",
    "    fips_numeric_claim = ExternalID(\n",
    "        prop_nr=fips_numeric,\n",
    "        value=row.fips_numeric,\n",
    "        references=references\n",
    "    )\n",
    "\n",
    "    claims = [\n",
    "        state_instance_of_claim,\n",
    "        located_in_us_claim,\n",
    "        iso_3166_claim,\n",
    "        fips_alpha_claim,\n",
    "        fips_numeric_claim\n",
    "    ]\n",
    "\n",
    "    add_item(\n",
    "        label=row.stateLabel,\n",
    "        description=row.stateDescription,\n",
    "        aliases=row.fips_alpha,\n",
    "        claims=claims\n",
    "    )\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "geokb",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "73445f04a821fa03c75b5864e622841100a6f63483b936d10ffa5383ef328dbe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
