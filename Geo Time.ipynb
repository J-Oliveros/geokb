{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook works through a structured source for the geologic time scale to introduce items into the GeoKB representing eon, era, period, sub-period, epoch, and age units that can be linked to from other related items. The source used is the 2020 version of the [International Chronostratigraphic Chart] as represented in the [timescale RDF structure](https://github.com/CGI-IUGS/timescale-data) from Simon Cox and Steve Richard. Following our principle of pragmatic semantics for the GeoKB where we are building out representations of reference concepts and entities only to the level of detail needed for our own specific use cases. If we need to go back later and bring in more content from one or more sources, we can do that based on building in and retaining solid provenance and linkages to resolvable identifiers.\n",
    "\n",
    "This particular case prompted me to rethink a few things in how we've laid out properties and classification structure within the GeoKB. This is the first time I've worked through processing what we want from a source that is organized against a suite of formal ontologies (most of this is part of mature GeoSciML work). Building a set of items within Wikibase that is structured on a more informal foundation within the context of a broad knowledge graph that will contain many other types of content forced me to narrow in a bit and think through the implications for this and other cases where we want to base a part of our system on other formal ontological encodings.\n",
    "\n",
    "I ended up narrowing in on just the names, the geochronological rank (eon, era, etc.), and the basic broader/narrower relationships. The latter prompted me to leverage the same formal time interval concepts from the OWL time ontology. For now, I restricted this to the intervalDuring and intervalContains properties, instantiated in the GeoKB as item-type properties pointing to the corresponding item representations for the higher level and lower level \"eras\" (the ISC GTS uses \"GeochronologicalEra\" as the higher level concept for all ranks, which I also followed in the GeoKB representation). Another approach, perhaps more in keeping with at least some Wikidata conventions, would have been to establish separate properties for eon, era, period, and so on to house claims that point a given item to its containing geoligical time period and the time periods it contains. One approach requires chasing down the meaning of the property and the other may require chasing down the further definition of the linked items. I chose to build a few new properties more in keeping with the Cox/Richard encoding, which is more semantically correct, and we'll have to see if it communicates and works in practice.\n",
    "\n",
    "I also introduced an explicit new property for IRI as an identifier to a presumably semantically robust resolver. For our purposes, this will indicate that a given item sources directly to that identifier as its foundation, giving is the linkage to go back to source for additional definition and characteristics.\n",
    "\n",
    "I also reworked a bit of what I had been trying to figure out with pointing a given property or entity in the GeoKB to some other place where information about that thing can be found. I used the owl:sameAs property concept here in the same way that the ICS GTS uses it (pointing in that case to DBPedia identifiers). I'll end up using this in place of \"related wikidata item\" and \"related wikidata property.\" I may also revisit this again and introduce a set of qualifiers on \"same as\" claims, clarifying exactly what the relationship is. I still need to deal with the dynamic that just because something in another knowledge graph is basically the same thing as something in our GeoKB, there are still some caveats that need to be applied in practice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wbmaker import WikibaseConnection\n",
    "from rdflib import Graph\n",
    "import re\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "geokb = WikibaseConnection(\"GEOKB_CLOUD\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I ended up using the 2020 RDF/TTL encoding of the ICS time scale from the GitHub source. I noticed that there is a 2023 graphical chart from the web site, and it may be that the maintenance of the underlying encoded information might have shifted elsewhere. We can track that down, but this should suffice for the time being. We still also need to figure out exactly how we are going to deal with changes in things like this over time within the GeoKB."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<References @222010 _References__references=[<Reference @b31850 _Reference__hash=None _Reference__snaks=<Snaks @b32cd0 snaks={'P70': [<Snak @b31810 _Snak__snaktype=<WikibaseSnakType.KNOWN_VALUE: 'value'> _Snak__property_number='P70' _Snak__hash=None _Snak__datavalue={'value': {'entity-type': 'item', 'numeric-id': 26294, 'id': 'Q26294'}, 'type': 'wikibase-entityid'} _Snak__datatype='wikibase-item'>]}> _Reference__snaks_order=[]>]>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "source_item_label = \"International Chronostratigraphic Chart v.2020\"\n",
    "source_item_qid = geokb.ref_lookup[source_item_label]\n",
    "source_item = geokb.wbi.item.get(source_item_qid)\n",
    "\n",
    "knowledgebase_source_claim = next((i for i in source_item.claims.get_json()[geokb.prop_lookup['instance of']] if i[\"mainsnak\"][\"datavalue\"][\"value\"][\"id\"] == geokb.class_lookup['knowledgebase source']), None)\n",
    "reference_url = knowledgebase_source_claim[\"references\"][0][\"snaks\"][geokb.prop_lookup['reference URL']][0][\"datavalue\"][\"value\"]\n",
    "\n",
    "references = geokb.models.References()\n",
    "references.add(\n",
    "    geokb.datatypes.Item(\n",
    "        prop_nr=geokb.prop_lookup['knowledge source'],\n",
    "        value=geokb.ref_lookup[source_item_label]\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Graph identifier=Na3d2792c34ae48a1b4a82e4d7ad2cbf3 (<class 'rdflib.graph.Graph'>)>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gts_2020 = Graph()\n",
    "gts_2020.parse(reference_url, format='ttl')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The turtle (TTL) representation of the ICS GTS is the same underlying RDF structure we have in Wikibase. I used the SPARQL method here to tease out what I want to work with in creating items. In this first pass, I am simply pulling each thing with a rank to get IRI identifiers, labels, and ranks. I go ahead and pull the time:intervalIn label to use in the description so that we get a more meaningful descriptive statement. The following codeblock pulls the query and builds a simplified data structure to work through (sample output shown).\n",
    "\n",
    "There is some issue in the data where I missed a couple (2) items based on the initial iteration of my query where I looked for anything with a gts:rank. That should essentially get all ranks, but I missed the all important Phanerozoic Eon record. The only think I found was an extraneous space in the label, but I'm still not sure why that would have caused the query to not return that record. This new query gets everything with a label and then options the other properties I want."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'iri': 'http://resource.geosciml.org/classifier/ics/ischart/MiddlePennsylvanian',\n",
       " 'label': 'Middle Pennsylvanian Epoch',\n",
       " 'geo_rank': 'Epoch',\n",
       " 'geo_rank_qid': 'Q26289',\n",
       " 'alt_label': 'Middle Pennsylvanian',\n",
       " 'description': 'a geologic Epoch in the Pennsylvanian Sub-period'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q = \"\"\"\n",
    "    SELECT ?item ?label ?geo_rank ?interval_in_label\n",
    "    WHERE {\n",
    "        ?item rdfs:label ?label .\n",
    "        OPTIONAL {\n",
    "            ?item gts:rank ?geo_rank .\n",
    "        }\n",
    "        OPTIONAL {\n",
    "            ?item time:intervalIn ?interval_in .\n",
    "            ?interval_in rdfs:label ?interval_in_label .\n",
    "        }\n",
    "    }\n",
    "\"\"\"\n",
    "\n",
    "geo_eras = []\n",
    "for r in gts_2020.query(q):\n",
    "    record = {\n",
    "        \"iri\": re.sub(\"<|>\", \"\", r[\"item\"].n3()),\n",
    "        \"label\": r[\"label\"].strip()\n",
    "    }\n",
    "    if r[\"geo_rank\"] is not None:\n",
    "        rank_str = re.sub(\"<|>\", \"\", r[\"geo_rank\"].n3()).split(\"/\")[-1]\n",
    "        record[\"geo_rank\"] = rank_str\n",
    "        record[\"geo_rank_qid\"] = geokb.class_lookup[rank_str] if rank_str in geokb.class_lookup else None\n",
    "        record[\"alt_label\"] = r[\"label\"].replace(rank_str, \"\").strip()\n",
    "    \n",
    "        if r[\"interval_in_label\"] is not None:\n",
    "            record[\"description\"] = f\"a geologic {rank_str} in the {r['interval_in_label']}\"\n",
    "        else:\n",
    "            record[\"description\"] = f\"a geologic {rank_str}\"\n",
    "\n",
    "        geo_eras.append(record)\n",
    "\n",
    "df_geo_eras = pd.DataFrame(geo_eras)\n",
    "geo_eras[99]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>iri</th>\n",
       "      <th>label</th>\n",
       "      <th>geo_rank</th>\n",
       "      <th>geo_rank_qid</th>\n",
       "      <th>alt_label</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [iri, label, geo_rank, geo_rank_qid, alt_label, description]\n",
       "Index: []"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eras_query = \"PREFIX%20wd%3A%20%3Chttps%3A%2F%2Fgeokb.wikibase.cloud%2Fentity%2F%3E%0APREFIX%20wdt%3A%20%3Chttps%3A%2F%2Fgeokb.wikibase.cloud%2Fprop%2Fdirect%2F%3E%0A%0ASELECT%20%3Fera%20%3Flabel%20%3Firi%0AWHERE%20%7B%0A%20%20VALUES%20%3Finstance_of%20%7B%20wd%3AQ26292%20wd%3AQ26288%20wd%3AQ26291%20wd%3AQ26289%20wd%3AQ26290%20wd%3AQ26293%20wd%3AQ26287%20%7D%0A%20%20%3Fera%20wdt%3AP1%20%3Finstance_of%20.%0A%20%20%3Fera%20rdfs%3Alabel%20%3Flabel%20.%0A%20%20%3Fera%20wdt%3AP80%20%3Firi%20.%0A%7D%0A\"\n",
    "\n",
    "df_wb_eras = geokb.wb_ref_data(query=eras_query)\n",
    "df_wb_eras[\"era\"] = df_wb_eras.era.apply(lambda x: x.split(\"/\")[-1])\n",
    "\n",
    "missing_eras = df_geo_eras[~df_geo_eras.iri.isin(df_wb_eras.iri)]\n",
    "missing_eras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, era in missing_eras.iterrows():\n",
    "    item = geokb.wbi.item.new()\n",
    "    item.labels.set('en', era[\"label\"])\n",
    "    item.descriptions.set('en', era[\"description\"])\n",
    "    item.aliases.set('en', era[\"alt_label\"])\n",
    "\n",
    "    claims = geokb.models.Claims()\n",
    "    claims.add(\n",
    "        geokb.datatypes.Item(\n",
    "            prop_nr=geokb.prop_lookup['instance of'],\n",
    "            value=era['geo_rank_qid'],\n",
    "            references=references\n",
    "        )\n",
    "    )\n",
    "\n",
    "    claims.add(\n",
    "        geokb.datatypes.ExternalID(\n",
    "            prop_nr=geokb.prop_lookup['IRI'],\n",
    "            value=era['iri'],\n",
    "            references=references\n",
    "        )\n",
    "    )\n",
    "\n",
    "    item.claims.add(claims)\n",
    "    response = item.write(summary=\"Added initial geochronologic era record from source\")\n",
    "    print(era[\"label\"], response.id)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rework through to add temporal relationships\n",
    "\n",
    "I went back and forth on the best way to bring the potentially somewhat complex relationships between geologic time units into the Wikibase context. This again gets at the principle toward pragmatic semantics, where we don't need to bring everything from perfectly solid reference sources into our GeoKB context if we don't need that information or level of depth in our system to reason against. If we ever do, we can go back and work through a process to augment what we have.\n",
    "\n",
    "Looking at the source (e.g., [Phanerozoic Eon](http://resource.geosciml.org/classifier/ics/ischart/Phanerozoic)) there's a lot that Cox and Richard brought together in terms of semantic depth. I haven't dealt with the boundary concepts at all yet, which is where we get interpreted point in time figures that I experimented with from another source previously. We also need to decide how deep we want to go in terms of the geologic time units within each broader GeologicEra type. We could use the transitive relationships to show every era, period, ephoch, and stage/age for a given eon, but I opted to simply work with the immediate narrower and broader relationships for now. The connections are there to walk the system as needed.\n",
    "\n",
    "I also debated whether we want to stick with the higher level SKOS concepts like broader/narrower as more generalized properties or stand in something that would put the different types of geochronologic units in as specific properties. It might be useful, in some ways, to work with the data showing specific eras within an eon without having to pull the type classification for the narrower units. However, this is partly how Wikidata has had such a proliferation of properties that mean essentially the same thing or perform the same basic function within the graph, so I opted to try and stick with higher level semantic concepts for a time and see how it works out in practice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_wb_eras = geokb.wb_ref_data(query=eras_query)\n",
    "df_wb_eras[\"era\"] = df_wb_eras.era.apply(lambda x: x.split(\"/\")[-1])\n",
    "\n",
    "wb_era_lookup = df_wb_eras.set_index(\"iri\")[\"era\"].to_dict()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_broader = \"\"\"\n",
    "    SELECT ?item ?label ?broader\n",
    "    WHERE {\n",
    "        ?item rdfs:label ?label .\n",
    "        ?item skos:broader ?broader .\n",
    "    }\n",
    "\"\"\"\n",
    "\n",
    "q_narrower = \"\"\"\n",
    "    SELECT ?item ?label ?narrower\n",
    "    WHERE {\n",
    "        ?item rdfs:label ?label .\n",
    "        ?item skos:narrower ?narrower .\n",
    "    }\n",
    "\"\"\"\n",
    "\n",
    "relationships = []\n",
    "for r in gts_2020.query(q_narrower):\n",
    "    relationships.append({\n",
    "        \"subject\": wb_era_lookup[re.sub(\"<|>\", \"\", r[\"item\"].n3())],\n",
    "        \"predicate\": geokb.prop_lookup['narrower'],\n",
    "        \"object\": wb_era_lookup[re.sub(\"<|>\", \"\", r[\"narrower\"].n3())]\n",
    "    })\n",
    "\n",
    "for r in gts_2020.query(q_broader):\n",
    "    relationships.append({\n",
    "        \"subject\": wb_era_lookup[re.sub(\"<|>\", \"\", r[\"item\"].n3())],\n",
    "        \"predicate\": geokb.prop_lookup['broader'],\n",
    "        \"object\": wb_era_lookup[re.sub(\"<|>\", \"\", r[\"broader\"].n3())]\n",
    "    })\n",
    "\n",
    "df_relationships = pd.DataFrame(relationships)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for era in df_relationships.groupby([\"subject\",\"predicate\"], as_index=False)[\"object\"].agg(list).to_dict(\"records\"):\n",
    "    item = geokb.wbi.item.get(era[\"subject\"])\n",
    "\n",
    "    claim_list = []\n",
    "    for o in era[\"object\"]:\n",
    "        claim_list.append(\n",
    "            geokb.datatypes.Item(\n",
    "                prop_nr=era[\"predicate\"],\n",
    "                value=o,\n",
    "                references=references\n",
    "            )\n",
    "        )\n",
    "    claims = geokb.models.Claims()\n",
    "    claims.add(claim_list)\n",
    "\n",
    "    item.claims.add(claims)\n",
    "    item.write(\n",
    "        summary=\"Fixed issue on multiple claims for broader and narrower geologic time periods\",\n",
    "        clear=True\n",
    "    )\n",
    "    print(era[\"subject\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "geokb",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8190544efbb2661b198b25bdaad02565f208a08fbde73732b97d4d23124b7122"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
