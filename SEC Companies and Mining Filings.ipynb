{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the sources for information we are interested in from a mining perspective in the GeoKB is a relatively new type of technical report required by the U.S. Securities and Exchange Commission (S-K 1300 Technical Report). These are similar to the National Instrument 43-101 Reports required by the Canadian Government, and they contain useful details on mineral prospects that can feed into mineral resource assessments.\n",
    "\n",
    "The SEC provides an API called EDGAR that facilitates access to S-K 1300 reports. Report format varies from PDF files (like the NI 43-101 reports) to HTML \"documents\" (essentially, small web sites with many HTML and image elements).\n",
    "\n",
    "From a knowledgebase perspective, working with these records indicates several entity types we need to make sense of:\n",
    "\n",
    "* Documents that we'll classify as something like \"government legal filing\"\n",
    "    * Classification properties for these documents\n",
    "    * Identifier properties that provide reasonably persistent, resolvable access to the documents\n",
    "    * Extracted subject matters indicated in the document texts\n",
    "* Commercial companies that will be a type of organizational entity\n",
    "    * Classification properties for these companies\n",
    "    * Identifier properties for companies that make them linkable to other systems\n",
    "\n",
    "Company/organization information is important to get nailed down as we work through these sources as these will be useful in other circumstances as well and will be needed in terms of tracking down and linking in other sources of information from both public and proprietary sources. The SEC has their own unique identifier called the Central Index Key (CIK).\n",
    "\n",
    "Along with the CIK identifiers, we may also want to explore the following additional international registry sources that can help us in disambiguating organizational entities and reaching out for further details:\n",
    "\n",
    "* [Global Legal Entitiy Identifier Foundation](https://www.gleif.org/en) - provides a persistent, resolvable identifier, API, and data dump with a ton of details on many commercial entities and their relationships; including a trace to ultimate parent entities\n",
    "* [OpenAlex](https://explore.openalex.org/) - a fully open registry mostly focused on academic publishing but including its own take on institutions, identifiers, and mapping\n",
    "\n",
    "There are other identifier systems/registries beyond these that apply here like the ISIN system, but most of them are either closed access or do not have a reasonable API or method for getting to useful data. Wikidata has a ton of the instititions we care about like mining companies, but it is somewhat fraught with semantic confusion issues. Where we can nail down a usable Wikidata Q identifier for a company, it may provide us with an avenue to get other identifiers, but we'll still need to run our own resolution to ensure they are valid mappings.\n",
    "\n",
    "## Approaching from the Company Identifier\n",
    "\n",
    "In looking over the SEC filings and in some discussions with assessment geologists, there are other artifacts from the SEC EDGAR source beyond the more formal S-K 1300 reports that could be useful (e.g., news releases with tables of production information). So, coming at this from the perspective of first identifying mining companies and then running routine queries to look for relevant filings may be a better way to approach the problem. We can establish entities for the companies in the knowledgebase, including relevant identifiers, and use those as a launching point to mine for useful documentation to bring into the knowledgebase and parse for claims."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from sec_api import QueryApi, FullTextSearchApi, MappingApi\n",
    "import requests\n",
    "import pandas as pd\n",
    "import swifter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sec_query_api = QueryApi(api_key=os.environ['SEC_EDGAR_KEY'])\n",
    "sec_mapping_api = MappingApi(api_key=os.environ['SEC_EDGAR_KEY'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mining Companies\n",
    "\n",
    "Figuring out exactly which companies registered with the SEC are involved in mining operations likely to be filing reports of use to the GeoKB is a little bit tricky as they might be classified in different sectors. \"Sector\" is one of the available query parameters in the [EDGAR Mapping API](https://sec-api.io/docs/mapping-api), which is where we can go after company information directly.\n",
    "\n",
    "Companies registered with the SEC are classified using the [Standard Industry Classification code](https://www.sec.gov/corpfin/division-of-corporation-finance-standard-industrial-classification-sic-code-list) system. These are available in the data, but unfortunately, they are not available as a query parameter. With a little bit of sleuthing, we can figure out the \"sector\" values where the appropriate SIC coded companies would be classified and then filter from there.\n",
    "\n",
    "I'm starting with a simplified list of SIC codes, from which we may need to expand if we find companies of interest in other sectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "mining_sector_codes = [\n",
    "    1000,\n",
    "    1040,\n",
    "    1090,\n",
    "    1400\n",
    "]\n",
    "\n",
    "df_companies = pd.DataFrame(sec_mapping_api.resolve(\"sector\", \"Basic Materials\"))\n",
    "df_mining_companies = df_companies[df_companies.sic.isin([str(i) for i in mining_sector_codes])].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>ticker</th>\n",
       "      <th>cik</th>\n",
       "      <th>cusip</th>\n",
       "      <th>exchange</th>\n",
       "      <th>isDelisted</th>\n",
       "      <th>category</th>\n",
       "      <th>sector</th>\n",
       "      <th>industry</th>\n",
       "      <th>sic</th>\n",
       "      <th>sicSector</th>\n",
       "      <th>sicIndustry</th>\n",
       "      <th>famaSector</th>\n",
       "      <th>famaIndustry</th>\n",
       "      <th>currency</th>\n",
       "      <th>location</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ALMADEN MINERALS LTD</td>\n",
       "      <td>AAU</td>\n",
       "      <td>1015647</td>\n",
       "      <td>020283305 020283107</td>\n",
       "      <td>NYSEMKT</td>\n",
       "      <td>False</td>\n",
       "      <td>ADR Common Stock</td>\n",
       "      <td>Basic Materials</td>\n",
       "      <td>Gold</td>\n",
       "      <td>1000</td>\n",
       "      <td>Mining</td>\n",
       "      <td>Metal Mining</td>\n",
       "      <td></td>\n",
       "      <td>Non-Metallic and Industrial Metal Mining</td>\n",
       "      <td>CAD</td>\n",
       "      <td>British Columbia; Canada</td>\n",
       "      <td>80ac18a59ea33ac49a4b4eb0c508e78c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ABTECH HOLDINGS INC</td>\n",
       "      <td>ABHD</td>\n",
       "      <td>1405858</td>\n",
       "      <td>00400H108 00400H207</td>\n",
       "      <td>OTC</td>\n",
       "      <td>True</td>\n",
       "      <td>Domestic Common Stock</td>\n",
       "      <td>Basic Materials</td>\n",
       "      <td>Uranium</td>\n",
       "      <td>1090</td>\n",
       "      <td>Mining</td>\n",
       "      <td>Miscellaneous Metal Ores</td>\n",
       "      <td></td>\n",
       "      <td>Non-Metallic and Industrial Metal Mining</td>\n",
       "      <td>USD</td>\n",
       "      <td>Arizona; U.S.A</td>\n",
       "      <td>97df33c6904298396f07475f5d484227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>AGNICO EAGLE MINES LTD</td>\n",
       "      <td>AEM</td>\n",
       "      <td>2809</td>\n",
       "      <td>008474108</td>\n",
       "      <td>NYSE</td>\n",
       "      <td>False</td>\n",
       "      <td>Canadian Common Stock</td>\n",
       "      <td>Basic Materials</td>\n",
       "      <td>Gold</td>\n",
       "      <td>1040</td>\n",
       "      <td>Mining</td>\n",
       "      <td>Gold And Silver Ores</td>\n",
       "      <td></td>\n",
       "      <td>Precious Metals</td>\n",
       "      <td>USD</td>\n",
       "      <td>Ontario; Canada</td>\n",
       "      <td>78de930fa8ae4077b3e540765185443b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>FIRST MAJESTIC SILVER CORP</td>\n",
       "      <td>AG</td>\n",
       "      <td>1308648</td>\n",
       "      <td>32076V103 32076R102</td>\n",
       "      <td>NYSE</td>\n",
       "      <td>False</td>\n",
       "      <td>Canadian Common Stock</td>\n",
       "      <td>Basic Materials</td>\n",
       "      <td>Silver</td>\n",
       "      <td>1040</td>\n",
       "      <td>Mining</td>\n",
       "      <td>Gold And Silver Ores</td>\n",
       "      <td></td>\n",
       "      <td>Precious Metals</td>\n",
       "      <td>USD</td>\n",
       "      <td>British Columbia; Canada</td>\n",
       "      <td>f933bb34a6eb75d8a744d8bc19e853fd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>ALAMOS GOLD INC</td>\n",
       "      <td>AGI</td>\n",
       "      <td>1178819</td>\n",
       "      <td>011532108 011527108</td>\n",
       "      <td>NYSE</td>\n",
       "      <td>False</td>\n",
       "      <td>Canadian Common Stock</td>\n",
       "      <td>Basic Materials</td>\n",
       "      <td>Gold</td>\n",
       "      <td>1040</td>\n",
       "      <td>Mining</td>\n",
       "      <td>Gold And Silver Ores</td>\n",
       "      <td></td>\n",
       "      <td>Precious Metals</td>\n",
       "      <td>USD</td>\n",
       "      <td>Ontario; Canada</td>\n",
       "      <td>a5d252de2675a3ed99ed7dd0fe930a75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>ALIO GOLD INC</td>\n",
       "      <td>ALO</td>\n",
       "      <td>1502154</td>\n",
       "      <td>88741P103 01627X108</td>\n",
       "      <td>NYSEMKT</td>\n",
       "      <td>True</td>\n",
       "      <td>ADR Common Stock</td>\n",
       "      <td>Basic Materials</td>\n",
       "      <td>Gold</td>\n",
       "      <td>1040</td>\n",
       "      <td>Mining</td>\n",
       "      <td>Gold And Silver Ores</td>\n",
       "      <td></td>\n",
       "      <td>Precious Metals</td>\n",
       "      <td>USD</td>\n",
       "      <td>British Columbia; Canada</td>\n",
       "      <td>f7f6b0f5d64f20af70da91b6614cc352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>AMERICAN LITHIUM CORP</td>\n",
       "      <td>AMLI</td>\n",
       "      <td>1699880</td>\n",
       "      <td>027259209 027259100</td>\n",
       "      <td>NASDAQ</td>\n",
       "      <td>False</td>\n",
       "      <td>Canadian Common Stock</td>\n",
       "      <td>Basic Materials</td>\n",
       "      <td>Other Industrial Metals &amp; Mining</td>\n",
       "      <td>1000</td>\n",
       "      <td>Mining</td>\n",
       "      <td>Metal Mining</td>\n",
       "      <td></td>\n",
       "      <td>Non-Metallic and Industrial Metal Mining</td>\n",
       "      <td>USD</td>\n",
       "      <td>British Columbia; Canada</td>\n",
       "      <td>15af68251c201b0bab0e800e12478e21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>AMERICAN EAGLE ENERGY CORP</td>\n",
       "      <td>AMZGQ</td>\n",
       "      <td>1282613</td>\n",
       "      <td>02554F300 02554F102 29759Y107</td>\n",
       "      <td>NYSEMKT</td>\n",
       "      <td>True</td>\n",
       "      <td>Domestic Common Stock</td>\n",
       "      <td>Basic Materials</td>\n",
       "      <td>Other Industrial Metals &amp; Mining</td>\n",
       "      <td>1000</td>\n",
       "      <td>Mining</td>\n",
       "      <td>Metal Mining</td>\n",
       "      <td></td>\n",
       "      <td>Non-Metallic and Industrial Metal Mining</td>\n",
       "      <td>USD</td>\n",
       "      <td>Colorado; U.S.A</td>\n",
       "      <td>12d3b11e04222a7d0fc3159ab41df766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>ALLIED NEVADA GOLD CORP</td>\n",
       "      <td>ANVGQ</td>\n",
       "      <td>1376610</td>\n",
       "      <td>019344100 448629105</td>\n",
       "      <td>NYSEMKT</td>\n",
       "      <td>True</td>\n",
       "      <td>Domestic Common Stock</td>\n",
       "      <td>Basic Materials</td>\n",
       "      <td>Gold</td>\n",
       "      <td>1040</td>\n",
       "      <td>Mining</td>\n",
       "      <td>Gold And Silver Ores</td>\n",
       "      <td></td>\n",
       "      <td>Precious Metals</td>\n",
       "      <td>USD</td>\n",
       "      <td>Nevada; U.S.A</td>\n",
       "      <td>a512cb7c6b11ef8ecfa2b8875d27257e</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>GOLDEN MINERALS CO</td>\n",
       "      <td>APXSQ</td>\n",
       "      <td>1011509</td>\n",
       "      <td>G04074103</td>\n",
       "      <td>NYSEMKT</td>\n",
       "      <td>True</td>\n",
       "      <td>Domestic Common Stock</td>\n",
       "      <td>Basic Materials</td>\n",
       "      <td>Other Precious Metals &amp; Mining</td>\n",
       "      <td>1040</td>\n",
       "      <td>Mining</td>\n",
       "      <td>Gold And Silver Ores</td>\n",
       "      <td></td>\n",
       "      <td>Precious Metals</td>\n",
       "      <td>USD</td>\n",
       "      <td>Colorado; U.S.A</td>\n",
       "      <td>58b8768e35aee777011cdbe0e863e5c4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          name ticker      cik                          cusip  \\\n",
       "2         ALMADEN MINERALS LTD    AAU  1015647            020283305 020283107   \n",
       "4          ABTECH HOLDINGS INC   ABHD  1405858            00400H108 00400H207   \n",
       "14      AGNICO EAGLE MINES LTD    AEM     2809                      008474108   \n",
       "18  FIRST MAJESTIC SILVER CORP     AG  1308648            32076V103 32076R102   \n",
       "21             ALAMOS GOLD INC    AGI  1178819            011532108 011527108   \n",
       "30               ALIO GOLD INC    ALO  1502154            88741P103 01627X108   \n",
       "35       AMERICAN LITHIUM CORP   AMLI  1699880            027259209 027259100   \n",
       "40  AMERICAN EAGLE ENERGY CORP  AMZGQ  1282613  02554F300 02554F102 29759Y107   \n",
       "43     ALLIED NEVADA GOLD CORP  ANVGQ  1376610            019344100 448629105   \n",
       "50          GOLDEN MINERALS CO  APXSQ  1011509                      G04074103   \n",
       "\n",
       "   exchange  isDelisted               category           sector  \\\n",
       "2   NYSEMKT       False       ADR Common Stock  Basic Materials   \n",
       "4       OTC        True  Domestic Common Stock  Basic Materials   \n",
       "14     NYSE       False  Canadian Common Stock  Basic Materials   \n",
       "18     NYSE       False  Canadian Common Stock  Basic Materials   \n",
       "21     NYSE       False  Canadian Common Stock  Basic Materials   \n",
       "30  NYSEMKT        True       ADR Common Stock  Basic Materials   \n",
       "35   NASDAQ       False  Canadian Common Stock  Basic Materials   \n",
       "40  NYSEMKT        True  Domestic Common Stock  Basic Materials   \n",
       "43  NYSEMKT        True  Domestic Common Stock  Basic Materials   \n",
       "50  NYSEMKT        True  Domestic Common Stock  Basic Materials   \n",
       "\n",
       "                            industry   sic sicSector  \\\n",
       "2                               Gold  1000    Mining   \n",
       "4                            Uranium  1090    Mining   \n",
       "14                              Gold  1040    Mining   \n",
       "18                            Silver  1040    Mining   \n",
       "21                              Gold  1040    Mining   \n",
       "30                              Gold  1040    Mining   \n",
       "35  Other Industrial Metals & Mining  1000    Mining   \n",
       "40  Other Industrial Metals & Mining  1000    Mining   \n",
       "43                              Gold  1040    Mining   \n",
       "50    Other Precious Metals & Mining  1040    Mining   \n",
       "\n",
       "                 sicIndustry famaSector  \\\n",
       "2               Metal Mining              \n",
       "4   Miscellaneous Metal Ores              \n",
       "14      Gold And Silver Ores              \n",
       "18      Gold And Silver Ores              \n",
       "21      Gold And Silver Ores              \n",
       "30      Gold And Silver Ores              \n",
       "35              Metal Mining              \n",
       "40              Metal Mining              \n",
       "43      Gold And Silver Ores              \n",
       "50      Gold And Silver Ores              \n",
       "\n",
       "                                famaIndustry currency  \\\n",
       "2   Non-Metallic and Industrial Metal Mining      CAD   \n",
       "4   Non-Metallic and Industrial Metal Mining      USD   \n",
       "14                           Precious Metals      USD   \n",
       "18                           Precious Metals      USD   \n",
       "21                           Precious Metals      USD   \n",
       "30                           Precious Metals      USD   \n",
       "35  Non-Metallic and Industrial Metal Mining      USD   \n",
       "40  Non-Metallic and Industrial Metal Mining      USD   \n",
       "43                           Precious Metals      USD   \n",
       "50                           Precious Metals      USD   \n",
       "\n",
       "                    location                                id  \n",
       "2   British Columbia; Canada  80ac18a59ea33ac49a4b4eb0c508e78c  \n",
       "4             Arizona; U.S.A  97df33c6904298396f07475f5d484227  \n",
       "14           Ontario; Canada  78de930fa8ae4077b3e540765185443b  \n",
       "18  British Columbia; Canada  f933bb34a6eb75d8a744d8bc19e853fd  \n",
       "21           Ontario; Canada  a5d252de2675a3ed99ed7dd0fe930a75  \n",
       "30  British Columbia; Canada  f7f6b0f5d64f20af70da91b6614cc352  \n",
       "35  British Columbia; Canada  15af68251c201b0bab0e800e12478e21  \n",
       "40           Colorado; U.S.A  12d3b11e04222a7d0fc3159ab41df766  \n",
       "43             Nevada; U.S.A  a512cb7c6b11ef8ecfa2b8875d27257e  \n",
       "50           Colorado; U.S.A  58b8768e35aee777011cdbe0e863e5c4  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_mining_companies.head(10)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Knowledgebase Mapping\n",
    "\n",
    "Looking at these records, we have a somewhat useful start to stubbing out organization/commercial company records in the GeoKB. This at least probably narrows down to companies we may care about for current use cases related to mineral resource assessments.\n",
    "\n",
    "We could go further and look for relevant SEC filings first or check other sources where we may have mention of these companies already. At some point, it probably doesn't hurt to have a start to records in our GeoKB for all of the companies filed with the SEC classified in one of the mining categories where we are likely to encounter them somewhere in our work. If we don't tie anything else to these entities for a while, that's okay.\n",
    "\n",
    "We could also track down other records for these companies in other registries like the LEI system mentioned above where we could have more robust information to start our records with.\n",
    "\n",
    "* Perhaps better primary name\n",
    "* Additional company names (aliases)\n",
    "* Some type of status indicator (have to track this down further and compare with other sources)\n",
    "* Jurisdiction may be the most useful indication of where the company is based or operating from. Many of these have \"legal addresses\" in Delaware (like thousands of other \"holding companies\")."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Starter function to tease out useful LEI information\n",
    "def lei_lookup(company_name):\n",
    "    lei_query = f\"https://api.gleif.org/api/v1/lei-records?page[size]=10&page[number]=1&filter[entity.names]={company_name}\"\n",
    "    r_lei = requests.get(lei_query)\n",
    "    lei_entity = r_lei.json()\n",
    "\n",
    "    if 'data' not in lei_entity or len(lei_entity['data']) != 1:\n",
    "        return\n",
    "    \n",
    "    lei_info = {\n",
    "        'lei': lei_entity['data'][0]['attributes']['lei'],\n",
    "        'legal_name': lei_entity['data'][0]['attributes']['entity']['legalName']['name'],\n",
    "        'other_names': lei_entity['data'][0]['attributes']['entity']['otherNames'],\n",
    "        'status': lei_entity['data'][0]['attributes']['entity']['status'],\n",
    "        'jurisdiction': lei_entity['data'][0]['attributes']['entity']['jurisdiction']\n",
    "    }\n",
    "\n",
    "    return lei_info\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PARAMOUNT GOLD NEVADA CORP\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'lei': '5493000CWEBEVDLIW256',\n",
       " 'legal_name': 'Paramount Gold Nevada Corp.',\n",
       " 'other_names': [],\n",
       " 'status': 'ACTIVE',\n",
       " 'jurisdiction': 'US-NV'}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sample_name = df_mining_companies.sample().iloc[0][\"name\"]\n",
    "print(sample_name)\n",
    "\n",
    "display(lei_lookup(\n",
    "    company_name=sample_name\n",
    "))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This additional information introduces some nuances we need to think about in modeling these entities into our knowledgebase. Other names has more useful information content beyond just a name string and language (both needed to encode into Wikibase). It also gives us a qualifier indicating the type of name, often indicating a former name. I've seen examples in Wikidata where someone tossed this into the alias as a parenthetical, but that's not a great way to handle things. We may want to introduce these as claims where we can propery encode the qualifier, potentially in addition to incorporating the name string into aliases for standard search operations.\n",
    "\n",
    "We could introduce an overall status type of property at a higher level of semantics, applying across a range of item types, using either specific item objects as values (e.g., \"LEI ACTIVE\") or general values with a qualifier indicating what kind of \"ACTIVE\" we mean or just use a reference on the claim to indicate where it comes from. Whatever we decide, we'll need to write down the design principle and use it consistently.\n",
    "\n",
    "We also have suggested claims pointing to a country (e.g., CA, US, etc.) and state/province (e.g., British Columbia, Nevada, etc.). The target object for these will come from a place name reference we need to build into the GeoKB for many purposes. The \"jurisdiction\" property from the LEI system represents the governmental jurisdictions under which the company operates, which leads to some kind of unique property in the GeoKB for this type of information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5f8ecfa84804562a690e974e9744f85",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pandas Apply:   0%|          | 0/317 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_mining_companies['lei'] = df_mining_companies['name'].swifter.apply(lambda x: lei_lookup(x))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Central point of facts\n",
    "\n",
    "One of the interesting dynamics we are pursuing with the GeoKB idea is to establish what will amount to a \"central point of facts\" that is dynamic in nature. Some of the operations we may undertake will be costly in terms of computational processing time like the above example. But once we go to the effort and encode what we want to use into our knowledgebase, we can then leverage it in lots of different ways. Some sources will \"demand\" that we build something to revisit them periodically for new and updated information, while others will be more of a one-time deal. Some sources will need to be revisited when we determine that there is other useful information to be had or we need to re-think how we encoded something.\n",
    "\n",
    "The above process essentially worked through 300+ records with individual queries in a pretty inefficient way, one record at a time hitting a REST API. We can actually send multiple names at once to the same API end point, but the results that come back have to be processed further to figure out matches to those names. We also ignored cases for now where a name comes up with more than one hit. That will all have to get worked out.\n",
    "\n",
    "If this particular case of working the LEI system is important enough in other use cases, we may want to consider a different approach where we load their bulk data (the \"Gold File\") somewhere into our own infrastructure (e.g., an Elasticsearch index) where we can run processing more efficiently at scale in the cloud with our own custom output. At a few hundred records, this is no big deal. Once we nail down the identifier mapping and gather a few useful details, we have our single point of facts to operate with. But we have to keep the reprocessing dynamic in mind, recognizing that nothing we put into the knowledgebase will ever remain completely static."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>lei_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ALMADEN MINERALS LTD</td>\n",
       "      <td>ALMADEN MINERALS LTD.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>FIRST MAJESTIC SILVER CORP</td>\n",
       "      <td>First Majestic Silver Corp.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>ALAMOS GOLD INC</td>\n",
       "      <td>ALAMOS GOLD INC.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>ALIO GOLD INC</td>\n",
       "      <td>Alio Gold Inc.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>AMERICAN LITHIUM CORP</td>\n",
       "      <td>AMERICAN LITHIUM CORP.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1011</th>\n",
       "      <td>PARAMOUNT GOLD NEVADA CORP</td>\n",
       "      <td>Paramount Gold Nevada Corp.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1013</th>\n",
       "      <td>RICHMONT MINES INC</td>\n",
       "      <td>Richmont Mines Inc.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1020</th>\n",
       "      <td>SEABRIDGE GOLD INC</td>\n",
       "      <td>SEABRIDGE GOLD INC.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1052</th>\n",
       "      <td>VIZSLA SILVER CORP</td>\n",
       "      <td>VIZSLA SILVER CORP.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1053</th>\n",
       "      <td>WMC RESOURCES LTD</td>\n",
       "      <td>BHP WESTERN MINING RESOURCES INTERNATIONAL PTY...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>114 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                            name  \\\n",
       "2           ALMADEN MINERALS LTD   \n",
       "18    FIRST MAJESTIC SILVER CORP   \n",
       "21               ALAMOS GOLD INC   \n",
       "30                 ALIO GOLD INC   \n",
       "35         AMERICAN LITHIUM CORP   \n",
       "...                          ...   \n",
       "1011  PARAMOUNT GOLD NEVADA CORP   \n",
       "1013          RICHMONT MINES INC   \n",
       "1020          SEABRIDGE GOLD INC   \n",
       "1052          VIZSLA SILVER CORP   \n",
       "1053           WMC RESOURCES LTD   \n",
       "\n",
       "                                               lei_name  \n",
       "2                                 ALMADEN MINERALS LTD.  \n",
       "18                          First Majestic Silver Corp.  \n",
       "21                                     ALAMOS GOLD INC.  \n",
       "30                                       Alio Gold Inc.  \n",
       "35                               AMERICAN LITHIUM CORP.  \n",
       "...                                                 ...  \n",
       "1011                        Paramount Gold Nevada Corp.  \n",
       "1013                                Richmont Mines Inc.  \n",
       "1020                                SEABRIDGE GOLD INC.  \n",
       "1052                                VIZSLA SILVER CORP.  \n",
       "1053  BHP WESTERN MINING RESOURCES INTERNATIONAL PTY...  \n",
       "\n",
       "[114 rows x 2 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_mining_companies_with_lei = df_mining_companies[df_mining_companies.lei.notnull()][[\"name\",\"lei\"]].copy()\n",
    "df_mining_companies_with_lei['lei_name'] = df_mining_companies_with_lei.lei.apply(lambda x: x['legal_name'])\n",
    "df_mining_companies_with_lei[[\"name\",\"lei_name\"]]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Out of our 317 \"mining companies\" registered with the SEC, we were able to find 114 pretty solid matches to the LEI system based on name. We don't absolutely know those are the same entity, but chances are pretty good because of the way we ran the searches. Looking at the results above, we can see some interesting things like the match on \"WMC RESOURCES LTD\" from the SEC EDGAR and the much more comprehensive legal name from the LEI registry. Maybe this doesn't matter all that much for our current use cases, but as we work to build on the knowledgebase foundation and go after other linked information, this might make a difference."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SEC Filings\n",
    "\n",
    "Assuming we use the combination of SEC mining company records with some matches to the LEI registry to stub out the start to company records in our GeoKB, we could then initiate routine data mining for relevant SEC findings based on the CIK identifiers and the SEC EDGAR API. We can start by exploring everything associated with a given CIK identifier to develop a better query/processing pathway to tease out what we want.\n",
    "\n",
    "Filings are also essentially static \"government legal filing\" entities from the standpoint of our knowledge model. Once we identify what we want and bring them into our system, we can build on them from that point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_sec_filings(cik):\n",
    "    query = {\n",
    "      \"query\": { \"query_string\": { \n",
    "          \"query\": \"cik:{cik}\",\n",
    "      } },\n",
    "      \"from\": \"0\",\n",
    "      \"size\": \"10\",\n",
    "      \"sort\": [{ \"filedAt\": { \"order\": \"desc\" } }]\n",
    "    }\n",
    "\n",
    "    return sec_query_api.get_filings(query)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "ename": "Exception",
     "evalue": "API error: 429 - {\"status\":429,\"error\":\"You send a lot of requests. We like that. But you exceeded the free query limit of 100 requests. Upgrade your account to get unlimited access. Visit sec-api.io for more.\"}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[53], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m df_mining_companies[\u001b[39m'\u001b[39m\u001b[39msec_filings\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m df_mining_companies\u001b[39m.\u001b[39;49mcik\u001b[39m.\u001b[39;49mswifter\u001b[39m.\u001b[39;49mapply(\u001b[39mlambda\u001b[39;49;00m x: query_sec_filings(x))\n",
      "File \u001b[0;32m/opt/anaconda3/envs/geokb/lib/python3.11/site-packages/swifter/swifter.py:310\u001b[0m, in \u001b[0;36mSeriesAccessor.apply\u001b[0;34m(self, func, convert_dtype, args, **kwds)\u001b[0m\n\u001b[1;32m    308\u001b[0m \u001b[39mwith\u001b[39;00m suppress_stdout_stderr_logging():\n\u001b[1;32m    309\u001b[0m     tmp_df \u001b[39m=\u001b[39m func(sample, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[0;32m--> 310\u001b[0m     sample_df \u001b[39m=\u001b[39m sample\u001b[39m.\u001b[39;49mapply(func, convert_dtype\u001b[39m=\u001b[39;49mconvert_dtype, args\u001b[39m=\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    311\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_apply(\n\u001b[1;32m    312\u001b[0m         np\u001b[39m.\u001b[39marray_equal(sample_df, tmp_df) \u001b[39m&\u001b[39m (\u001b[39mhasattr\u001b[39m(tmp_df, \u001b[39m\"\u001b[39m\u001b[39mshape\u001b[39m\u001b[39m\"\u001b[39m)) \u001b[39m&\u001b[39m (sample_df\u001b[39m.\u001b[39mshape \u001b[39m==\u001b[39m tmp_df\u001b[39m.\u001b[39mshape),\n\u001b[1;32m    313\u001b[0m         error_message\u001b[39m=\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mVectorized function sample doesn\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt match pandas apply sample.\u001b[39m\u001b[39m\"\u001b[39m),\n\u001b[1;32m    314\u001b[0m     )\n\u001b[1;32m    315\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_obj, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/geokb/lib/python3.11/site-packages/pandas/core/series.py:4771\u001b[0m, in \u001b[0;36mSeries.apply\u001b[0;34m(self, func, convert_dtype, args, **kwargs)\u001b[0m\n\u001b[1;32m   4661\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply\u001b[39m(\n\u001b[1;32m   4662\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m   4663\u001b[0m     func: AggFuncType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4666\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[1;32m   4667\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m DataFrame \u001b[39m|\u001b[39m Series:\n\u001b[1;32m   4668\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   4669\u001b[0m \u001b[39m    Invoke function on values of Series.\u001b[39;00m\n\u001b[1;32m   4670\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4769\u001b[0m \u001b[39m    dtype: float64\u001b[39;00m\n\u001b[1;32m   4770\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 4771\u001b[0m     \u001b[39mreturn\u001b[39;00m SeriesApply(\u001b[39mself\u001b[39;49m, func, convert_dtype, args, kwargs)\u001b[39m.\u001b[39;49mapply()\n",
      "File \u001b[0;32m/opt/anaconda3/envs/geokb/lib/python3.11/site-packages/pandas/core/apply.py:1123\u001b[0m, in \u001b[0;36mSeriesApply.apply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1120\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapply_str()\n\u001b[1;32m   1122\u001b[0m \u001b[39m# self.f is Callable\u001b[39;00m\n\u001b[0;32m-> 1123\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mapply_standard()\n",
      "File \u001b[0;32m/opt/anaconda3/envs/geokb/lib/python3.11/site-packages/pandas/core/apply.py:1174\u001b[0m, in \u001b[0;36mSeriesApply.apply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1172\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1173\u001b[0m         values \u001b[39m=\u001b[39m obj\u001b[39m.\u001b[39mastype(\u001b[39mobject\u001b[39m)\u001b[39m.\u001b[39m_values\n\u001b[0;32m-> 1174\u001b[0m         mapped \u001b[39m=\u001b[39m lib\u001b[39m.\u001b[39;49mmap_infer(\n\u001b[1;32m   1175\u001b[0m             values,\n\u001b[1;32m   1176\u001b[0m             f,\n\u001b[1;32m   1177\u001b[0m             convert\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconvert_dtype,\n\u001b[1;32m   1178\u001b[0m         )\n\u001b[1;32m   1180\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(mapped) \u001b[39mand\u001b[39;00m \u001b[39misinstance\u001b[39m(mapped[\u001b[39m0\u001b[39m], ABCSeries):\n\u001b[1;32m   1181\u001b[0m     \u001b[39m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[1;32m   1182\u001b[0m     \u001b[39m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[1;32m   1183\u001b[0m     \u001b[39mreturn\u001b[39;00m obj\u001b[39m.\u001b[39m_constructor_expanddim(\u001b[39mlist\u001b[39m(mapped), index\u001b[39m=\u001b[39mobj\u001b[39m.\u001b[39mindex)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/geokb/lib/python3.11/site-packages/pandas/_libs/lib.pyx:2924\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n",
      "Cell \u001b[0;32mIn[53], line 1\u001b[0m, in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[0;32m----> 1\u001b[0m df_mining_companies[\u001b[39m'\u001b[39m\u001b[39msec_filings\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m df_mining_companies\u001b[39m.\u001b[39mcik\u001b[39m.\u001b[39mswifter\u001b[39m.\u001b[39mapply(\u001b[39mlambda\u001b[39;00m x: query_sec_filings(x))\n",
      "Cell \u001b[0;32mIn[52], line 11\u001b[0m, in \u001b[0;36mquery_sec_filings\u001b[0;34m(cik)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mquery_sec_filings\u001b[39m(cik):\n\u001b[1;32m      2\u001b[0m     query \u001b[39m=\u001b[39m {\n\u001b[1;32m      3\u001b[0m       \u001b[39m\"\u001b[39m\u001b[39mquery\u001b[39m\u001b[39m\"\u001b[39m: { \u001b[39m\"\u001b[39m\u001b[39mquery_string\u001b[39m\u001b[39m\"\u001b[39m: { \n\u001b[1;32m      4\u001b[0m           \u001b[39m\"\u001b[39m\u001b[39mquery\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39mcik:\u001b[39m\u001b[39m{cik}\u001b[39;00m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      8\u001b[0m       \u001b[39m\"\u001b[39m\u001b[39msort\u001b[39m\u001b[39m\"\u001b[39m: [{ \u001b[39m\"\u001b[39m\u001b[39mfiledAt\u001b[39m\u001b[39m\"\u001b[39m: { \u001b[39m\"\u001b[39m\u001b[39morder\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39mdesc\u001b[39m\u001b[39m\"\u001b[39m } }]\n\u001b[1;32m      9\u001b[0m     }\n\u001b[0;32m---> 11\u001b[0m     \u001b[39mreturn\u001b[39;00m sec_query_api\u001b[39m.\u001b[39;49mget_filings(query)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/geokb/lib/python3.11/site-packages/sec_api/index.py:47\u001b[0m, in \u001b[0;36mQueryApi.get_filings\u001b[0;34m(self, query)\u001b[0m\n\u001b[1;32m     45\u001b[0m         handle_api_error(response)\n\u001b[1;32m     46\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m---> 47\u001b[0m     handle_api_error(response)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/geokb/lib/python3.11/site-packages/sec_api/index.py:21\u001b[0m, in \u001b[0;36mhandle_api_error\u001b[0;34m(response)\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mhandle_api_error\u001b[39m(response):\n\u001b[0;32m---> 21\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mException\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mAPI error: \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m - \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(response\u001b[39m.\u001b[39mstatus_code, response\u001b[39m.\u001b[39mtext))\n",
      "\u001b[0;31mException\u001b[0m: API error: 429 - {\"status\":429,\"error\":\"You send a lot of requests. We like that. But you exceeded the free query limit of 100 requests. Upgrade your account to get unlimited access. Visit sec-api.io for more.\"}"
     ]
    }
   ],
   "source": [
    "df_mining_companies['sec_filings'] = df_mining_companies.cik.swifter.apply(lambda x: query_sec_filings(x))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wah...wah...wah...\n",
    "\n",
    "I should have anticipated this issue; I just hadn't keyed in on the \"Pricing\" menu item at the top of the SEC EDGAR API site. Many groups like this (including government) are going this route to control costs for offering these kinds of services. It sucks and kind of runs counter to open data policies, but it's the reality we have to deal with.\n",
    "\n",
    "Raw EDGAR data for bulk download seems to be available in a [monthly archive](https://www.sec.gov/Archives/edgar/monthly/). (This is how some government agencies are able to claim that they provide open data with things like their APIs considered to be over and above that basic service. Grrr!) It's stored in their foundational XML structure, and it looks like there are some methods in the [Python package](https://pypi.org/project/sec-api/#xbrl-to-json-converter-api) for transforming this to JSON. Notionally, we could figure out some kind of bulk download and do whatever we want with the data from that point on our own infrastructure. But we only need a very small slice of what they have for a small fraction of companies the SEC regulates. Another approach could be to set up a process that limits daily requests (I assume it's 100 requests/day), slowly gathering what we need as a baseline, and then picking up updates incrementally as needed."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building GeoKB Items\n",
    "\n",
    "Stymied with the API throttle for SEC EDGAR, we can revisit the process of building items for our companies. I'm also somewhat stuck there at the moment because of an issue I'm having with our pilot Wikibase instance and an error I'm getting on items after building claims (see the Initialize GeoKB notebook). But it would be useful to take this exercise to the point of exploring how we'd model commercial company items into the GeoKB.\n",
    "\n",
    "There are a couple of fundamental approaches we might take to the process of loading items and claims into the GeoKB. One approach could be to get data into a common format and then present records to a processor somewhere. This is essentially how things work with the [QuickStatements](https://www.wikidata.org/wiki/Help:QuickStatements) tool. This is a longstanding tool developed to operate Wikidata, and we're working to get it spun up now as an option for our GeoKB.\n",
    "\n",
    "QuickStatements scripts are essentially read line by line as a series of commands to take actions on a Wikibase instance. The QuickStatements interface will also accept tabular records in a particular structure as CSV, and there are some nice mature tools in OpenRefine for building out a QuickStatements structure. Rather than us coming up with our own tooling for this, we're going to try to stick with what we can with the QuickStatements/OpenRefine tooling for that approach.\n",
    "\n",
    "The other approach to this is following a path that is also pretty mature in Wikidata/Wikibase - building bots. These are essentially purpose-built tools designed to take some type of action, either introducing new entities, claims, qualifiers, and references or taking some transformational action on existing information in a Wikibase instance. This is what I've been exploring for initializing the GeoKB with our properties and classification options.\n",
    "\n",
    "This notebook exploration of SEC companies and filings could go either route. I'll take a few steps here down the path of working this up as a bot using the pywikibot package. I'm including a developing set of functions that we'll eventually move out into their own package somewhere to import into a process like this once we "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Company Modeling and Semantics\n",
    "\n",
    "Building on the notes above on \"knowledgebase mapping,\" we need to make some decisions about what to send into the GeoKB. Here is some of my reasoning:\n",
    "\n",
    "* The primary label is important as it will show up in all kinds of reports and will be used as a human-centric identifier for companies. It looks like the LEI legal name is sometimes a little better or more comprehensive, so we'll prefer that as the primary label where we could get a match. We could try and title case the names that are all caps and may come back to that later, but I'll leave those for now.\n",
    "* Where the SEC name is different from the LEI legal name, we'll add that in as an alias along with any other names turned up from the LEI records. We'll just use English language names for now until we work through multilingual support in our Wikibase instance.\n",
    "* Descriptions are also important basic information on every item. When we put information together into different contexts, we often want to see a short description for things to help distinguish similarly named entities. This can also be done through classification (e.g., \"instance of\" claims), but a description can also suffice. Making up descriptions can get a bit tricky, though, in that we don't want to introduce conflicting semantics or necessarily have to keep up with changes in other parts of a record.\n",
    "* We are trying to keep higher level classification as simple as possible and not go down the rabbit hole that Wikidata has on incredibly specific properties and classifiers. We already have entity>organization from our initialization work so far. We might want to build in entity>organization>commercial company, but I don't think we want to go deeper than that at this point. Rather, we can build on the classification by adding in other logical properties that our exploration of the SEC and LEI sources suggest. For instance, the sicSector and sicIndustry properties from the SEC EDGAR records seem to be useful descriptive concepts to further classify commercial companies that we should be able to apply in other cases. Process-wise, that means we need to build out additional items as a reference base so we have something to link to on the other end of a property.\n",
    "* The SEC records include both the SIC classification for industries and an older industry classification system (FAMA). The terminology used in the FAMA classification seems like it might be more useful for our purposes; less prone to conflation with other concepts like the mineral commodities that a specific mining company might be associated with through other data linking. We can include both and see how it plays out in practice. Taking a more simplistic approach, we might put these in as \"subject matter\" claims, letting the characterization of the objects for those claims, references, and any qualifiers that might be appropriate handle the deeper level significance. In any case, we need to also build out the SIC and FAMA industry classification references in our GeoKB for use.\n",
    "* The \"sector\" and \"industry\" classifiers that appear to be specific to SEC EDGAR seem to be pertinent to SEC's way of looking at the world and perhaps not as useful for us to bring into the GeoKB. Values like \"Gold\" and \"Silver\" as \"industries\" could complicate our semantics, essentially meaning we would need to make those items in the GeoKB not only instances of \"mineral commodity\" and \"chemical element\" but also something totally different like \"SEC industry.\" \n",
    "* We need to handle the intersection of the SEC EDGAR location property with the LEI jurisdiction property. These look like they logically align, but we'll have to see if that's actually the case. In any case, we will want to introduce these concepts into our system along with their associated reference foundation (place names). Both \"location\" and \"jurisdiction\" are somewhat problematic and contextual as concepts. The more detailed location information (legal address, headquarters) from LEI is much more specific but perhaps less useful. One approach would be to take the very high level concept of any kind of location as the property, point it to reference items like \"United States of America\" and \"Nevada,\" and qualify those with some kind of descriptor that indicates that the values indicate a governmental jurisdiction under which the commercial company entity is governed. Or we could create a specific property like \"governance jurisdiction\" that comes along with that specific semantic significance and simply point at the reference for the information.\n",
    "* There are a number of different identifiers for our recordset. The CIK from SEC EDGAR and LEI identifier seem to be the most important as we can leverage those as unique, persistent, resolvable identifiers for linkages to other information. The stock ticker and CUSIP identifiers could be useful for some kinds of linkages, but we may just ignore those for now as not really pertinent to our current GeoKB use cases. What stock exchange a company trades on is not really all that useful for our purposes either."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reference Sources Specific to this Exploration\n",
    "\n",
    "Before proceeding too far with building out company items, we need to introduce some fundamental reference sources to the knowledgebase. Company items themselves are a reference source for the document items (e.g., S-K 1300 reports) that we are really after here as the heart of our use case. The notes above suggest we need to build a process to add in the following:\n",
    "\n",
    "* Standard Industrial Classification (SIC) code list\n",
    "    * Usable source - https://www.sec.gov/corpfin/division-of-corporation-finance-standard-industrial-classification-sic-code-list\n",
    "    * Needs a new high level classifier - \"industrial classification\"\n",
    "    * Need to decide if we will bring all of these into the GeoKB now or just those we're focused on for mining industries\n",
    "* FAMA (\"French\") codes\n",
    "    * This is an interesting case that we will run into elsewhere in that the fundamental source for this classification system is essentially copyrighted with no clear license for use. It is part of an academic project and longstanding financial analysis effort by a Dartmouth professor (https://mba.tuck.dartmouth.edu/pages/faculty/ken.french/Data_Library/det_48_ind_port.html). We can take SEC values and put those terms into our GeoKB source for use, but we couldn't really leitimately go and process the entire source for these if we wanted to do that without clarifying the license issue.\n",
    "    * I think we can basically just take the values we encounter on companies we care about for our use case, introduce them as instances of \"industrial classification,\" attribute them in their description, and reference them to where we get them from SEC EDGAR. There might be some better ways to model these, but we'll have to think that through as a general rule in dealing with copyrighted/ambiguous license information content.\n",
    "* CIK and LEI identifiers\n",
    "    * We're following the Wikidata approach on identifiers, setting them up with their resolvers built in so that humans and machines can follow them to their source, resolve them, and get whatever functionality they indicate. We need to work that out for this case still to see if we can get to something that supports content negotiation (meaning the same URL pattern can work for humans and machines).\n",
    "\n",
    "## Other Reference Sources\n",
    "\n",
    "The place name source is not at all specific here, so I'll be working that one up in a separate notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "sparql_endpoint = os.environ['SPARQL_ENDPOINT']\n",
    "wb_domain = os.environ['WB_DOMAIN']\n",
    "geokb_init_sheet_id = '1dbuKc4cZJz0YY81B2xWXM5fId6gWgzmQar3hg3CI0Rw'\n",
    "\n",
    "accepted_languages = ['en']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start to deployable functions\n",
    "from utils import (\n",
    "    get_wb\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "geokb_site = get_wb('geokb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "geokb",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "bf3b427550abc636388c726c622fd95adcdc42f0880499fad9fd5e67fc347911"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
