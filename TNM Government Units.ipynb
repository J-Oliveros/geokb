{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ddd1764a-b9b7-49a1-a325-d5f189ff41a6",
   "metadata": {},
   "source": [
    "This notebook works through the process of adding county-level government units to the GeoKB using the government units source from the USGS National Map. While there are other sources we could work against, this provides a way to demonstrate operating against National Map staged data in the AWS cloud, something we often need to do with other data assets such as Lidar point clouds for processing custom DEMs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ec7a6054-72b6-435e-920b-a25e6a275e91",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import awswrangler as wr\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "from io import BytesIO\n",
    "import zipfile\n",
    "from joblib import Parallel, delayed\n",
    "from tqdm import tqdm\n",
    "\n",
    "from utils import sparql_query, property_lookup\n",
    "\n",
    "from wikibaseintegrator.wbi_config import config as wbi_config\n",
    "from wikibaseintegrator import WikibaseIntegrator, wbi_login, wbi_helpers\n",
    "from wikibaseintegrator.datatypes import Item, String, ExternalID, URL, GlobeCoordinate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "8808c156-1c1b-4356-8ab8-8d714ff3d945",
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_resource = boto3.resource('s3')\n",
    "\n",
    "wbi_config['MEDIAWIKI_API_URL'] = os.environ[\"WC_MEDIAWIKI_API_URL\"]\n",
    "wbi_config['SPARQL_ENDPOINT_URL'] = os.environ['WC_SPARQL_ENDPOINT_URL']\n",
    "wbi_config['WIKIBASE_URL'] = os.environ['WC_WIKIBASE_URL']\n",
    "\n",
    "# Use bot account for this specific task\n",
    "geokb_auth = wbi_login.Login(\n",
    "    user=os.environ[\"WC_BOT_INIT\"],\n",
    "    password=os.environ[\"WC_PASS_INIT\"]\n",
    ")\n",
    "wbi = WikibaseIntegrator(login=geokb_auth)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65075400-e32f-43fa-a81f-fe44bbe0de27",
   "metadata": {},
   "source": [
    "### TNM Staged Products\n",
    "\n",
    "There is lots of stuff in the StagedProducts folder of the prd-tnm bucket that could be interesting in other use cases. the following gets us a list of the zip files containing geopackage forms of the state files. I'm going this route instead of processing the national file to use the more open standard format (national is only in an Esri GDB)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c9117f47-955d-4702-af6d-d46916bcb27a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['s3://prd-tnm/StagedProducts/GovtUnit/GPKG/GOVTUNIT_Alabama_State_GPKG.zip',\n",
       " 's3://prd-tnm/StagedProducts/GovtUnit/GPKG/GOVTUNIT_Alaska_State_GPKG.zip',\n",
       " 's3://prd-tnm/StagedProducts/GovtUnit/GPKG/GOVTUNIT_American_Samoa_State_GPKG.zip',\n",
       " 's3://prd-tnm/StagedProducts/GovtUnit/GPKG/GOVTUNIT_Arizona_State_GPKG.zip',\n",
       " 's3://prd-tnm/StagedProducts/GovtUnit/GPKG/GOVTUNIT_Arkansas_State_GPKG.zip']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tnm_gov_units = wr.s3.list_objects('s3://prd-tnm/StagedProducts/GovtUnit/GPKG')\n",
    "tnm_state_gpkg = [i for i in tnm_gov_units if i.endswith('.zip')]\n",
    "tnm_state_gpkg[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "660b7d27-128e-42ae-97ef-7cb07dc2aaaf",
   "metadata": {},
   "source": [
    "The first function reads a zip file into memory and then loads it into geodataframe for processing. This saves having to extract the file to disc. It would be better if we used gzip or another file compressor as those can be read directly with some tools without going through this kind of process. This is not a super clean engineered function, and it could use a bunch of error trapping. I just happen to know that this is a pretty stable source and this should work for my immediate purposes. These data don't change real often, but we'll have to harden this eventually.\n",
    "\n",
    "The second is just a simple helper for the final push of a new item to the GeoKB."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6adee891-da21-4b90-bacb-cb18f0fb12b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gdf_from_s3_zip(path):\n",
    "    # Parse out the bucket and key\n",
    "    bucket = path.split(\"/\")[2]\n",
    "    key = \"/\".join(path.split(\"/\")[3:])\n",
    "    \n",
    "    # Get the file object\n",
    "    file_obj = s3_resource.Object(\n",
    "        bucket_name=bucket, \n",
    "        key=key\n",
    "    )\n",
    "    # Read the file object into a buffer\n",
    "    buffer = BytesIO(file_obj.get()[\"Body\"].read())\n",
    "    # Put the zip in the buffer\n",
    "    z = zipfile.ZipFile(buffer)\n",
    "    \n",
    "    # Figure out the gpkg file name\n",
    "    gpkg_file = next((i for i in z.namelist() if i.endswith('.gpkg')), None)\n",
    "    \n",
    "    if gpkg_file is None:\n",
    "        return\n",
    "    # Pull the file into a geodataframe\n",
    "    return gpd.read_file(z.open(gpkg_file))\n",
    "\n",
    "def get_unit_geo(s3_path):\n",
    "    # Get the gpkg\n",
    "    state_units = gdf_from_s3_zip(s3_path)\n",
    "\n",
    "    # Add a centroid so we can populate coordinate location\n",
    "    state_units['coordinate_location'] = state_units.geometry.apply(lambda x: x.centroid)\n",
    "    state_units['lon'] = state_units['coordinate_location'].x\n",
    "    state_units['lat'] = state_units['coordinate_location'].y\n",
    "\n",
    "    # Add just the data we need\n",
    "    prepped_data = pd.DataFrame(state_units[[\n",
    "            \"stco_fipscode\",\n",
    "            \"gnis_name\",\n",
    "            \"lon\",\n",
    "            \"lat\"\n",
    "        ]]\n",
    "    )\n",
    "    \n",
    "    return prepped_data\n",
    "\n",
    "def add_item(label, description, aliases, claims):\n",
    "    item = wbi.item.new()\n",
    "\n",
    "    item.labels.set(language='en', value=label)\n",
    "    item.descriptions.set(language='en', value=description)\n",
    "    item.aliases.set(language='en', values=aliases)\n",
    "    item.claims.add(claims)\n",
    "\n",
    "    item.write()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "275b042f-0606-4cc4-bfe7-c30dc443bebd",
   "metadata": {
    "tags": []
   },
   "source": [
    "# GeoKB Properties\n",
    "\n",
    "We need to know what properties we are using to put information from this or any source into the GeoKB. I put a function in the utils.py that gets all properties via SPARQL and puts them in a simple dict so we can call \"P\" identifiers by name. For this case, we'll be using a number of the ExternalID properties like the FIPS codes along with the GNIS identifier.\n",
    "\n",
    "I'm going to leave off the related wikidata item for now. We can use Wikidata's own use of FIPS codes and GNIS identifiers to pull back items claiming to be associated with those, but it is just a claim. We need to trust but verify if we want to leverage the linkage to do anything like get additional characteristics.\n",
    "\n",
    "From the gov units schema, we are really just focused on the following properties:\n",
    "\n",
    "* stco_fipscode - gives us a linkage to other systems and assets\n",
    "* county_name - short name of the county used as an alias\n",
    "* gnis_id - gives us a linkage to other systems and assets\n",
    "* gnis_name - primary label with better context\n",
    "* coordinate_location - computed centroid of the county boundary entered for informational purposes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "185c4a17-6b47-4713-bfe6-199f8d07e80b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'instance of': 'P1',\n",
       " 'subclass of': 'P2',\n",
       " 'reference item': 'P3',\n",
       " 'reference url': 'P4',\n",
       " 'reference statement': 'P5',\n",
       " 'coordinate location': 'P6',\n",
       " 'publication date': 'P7',\n",
       " 'subject matter': 'P8',\n",
       " 'ranking': 'P9',\n",
       " 'ISO 3166-1 alpha-2 code': 'P10',\n",
       " 'located in the administrative territorial entity': 'P11',\n",
       " 'ISO 3166-2 code': 'P12',\n",
       " 'FIPS 5-2 alpha': 'P13',\n",
       " 'FIPS 5-2 numeric': 'P14',\n",
       " 'corresponding wikidata property': 'P15',\n",
       " 'related wikidata item': 'P16',\n",
       " 'element symbol': 'P17',\n",
       " 'SEDAR Identifier': 'P18',\n",
       " 'MRDS commodity code': 'P19',\n",
       " 'USGS Thesaurus ID': 'P20',\n",
       " 'GNIS ID': 'P21',\n",
       " 'FIPS 6-4': 'P22'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "geokb_props = property_lookup(wbi_config['SPARQL_ENDPOINT_URL'])\n",
    "geokb_props"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1dffc501-588d-4d0c-9bbb-65ee12f70184",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'item': 'https://geokb.wikibase.cloud/entity/Q230',\n",
       "  'itemLabel': 'Michigan',\n",
       "  'fips_code': '26'},\n",
       " {'item': 'https://geokb.wikibase.cloud/entity/Q231',\n",
       "  'itemLabel': 'Louisiana',\n",
       "  'fips_code': '22'},\n",
       " {'item': 'https://geokb.wikibase.cloud/entity/Q232',\n",
       "  'itemLabel': 'Oklahoma',\n",
       "  'fips_code': '40'},\n",
       " {'item': 'https://geokb.wikibase.cloud/entity/Q233',\n",
       "  'itemLabel': 'California',\n",
       "  'fips_code': '06'},\n",
       " {'item': 'https://geokb.wikibase.cloud/entity/Q234',\n",
       "  'itemLabel': 'Georgia',\n",
       "  'fips_code': '13'}]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We need our identifiers for states so we can establish the linkage\n",
    "# This will also drive what gov units we get, because we don't yet have the territories\n",
    "query_us_states = \"\"\"\n",
    "PREFIX wd: <%(wb_domain)s/entity/>\n",
    "PREFIX wdt: <%(wb_domain)s/prop/direct/>\n",
    "\n",
    "SELECT DISTINCT ?item ?itemLabel ?fips_code\n",
    "WHERE { ?item  wdt:P1  wd:Q229 . \n",
    "       ?item wdt:P14 ?fips_code .\n",
    "        SERVICE wikibase:label \n",
    "          { bd:serviceParam  wikibase:language  \"en\" . } \n",
    "      }\n",
    "\"\"\" % {'wb_domain': os.environ['WC_WIKIBASE_URL']}\n",
    "\n",
    "geokb_states = sparql_query(\n",
    "    endpoint=wbi_config['SPARQL_ENDPOINT_URL'],\n",
    "    query=query_us_states,\n",
    "    output='dict'\n",
    ")\n",
    "geokb_states[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c64d75a7-98a7-4814-b124-b8157a238ddb",
   "metadata": {},
   "source": [
    "### Entity/claim processing\n",
    "\n",
    "A simple serial loop may seem like a dumb way to do this in committing information to the GeoKB. There are some interesting processing ideas for handling all of this a lot faster and taking advantage of parallel processing. This [project](https://github.com/UB-Mannheim/RaiseWikibase), in particular, is something I'm looking into. However, we are still spinning all this up and working through the limitations of our system. For things like this where we're only dealing with a pretty small number of records, it's not that big a deal to take a little time to complete."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "555d976e-0f5b-4def-a297-cce031cbdd21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set universal properties\n",
    "claim_instance_of = Item(\n",
    "    prop_nr=geokb_props['instance of'],\n",
    "    value='Q481' # U.S. County\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d918627-6d3e-4c4d-8335-768fe8a83f4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for st in geokb_states[1:]: # I ran one state as a test to make sure it all worked\n",
    "    print(\"STARTED PROCESSING:\", st['itemLabel'])\n",
    "    geokb_id = st['item'].split('/')[-1]\n",
    "\n",
    "    # Get the appropriate S3 file to process\n",
    "    gov_unit_s3_path = next((i for i in tnm_state_gpkg if st['itemLabel'].replace(' ', '_') in i), None)\n",
    "    \n",
    "    # Set up an http reference\n",
    "    http_ref = gov_unit_s3_path.replace('s3://prd-tnm/', 'https://prd-tnm.s3.amazonaws.com/')\n",
    "    \n",
    "    # Set up reference source to add to claims\n",
    "    ref_source = URL(\n",
    "        prop_nr=geokb_props['reference url'],\n",
    "        value=http_ref\n",
    "    )\n",
    "    \n",
    "    claim_county_in_state = Item(\n",
    "        prop_nr=geokb_props['located in the administrative territorial entity'],\n",
    "        value=geokb_id,\n",
    "        references=[[ref_source]]\n",
    "    )  \n",
    "    \n",
    "    # Get the gpkg\n",
    "    state_units = gdf_from_s3_zip(gov_unit_s3_path)\n",
    "    # Add a centroid so we can populate coordinate location\n",
    "    # state_units['coordinate_location'] = state_units.geometry.apply(lambda x: x.centroid)\n",
    "    # state_units['lon'] = state_units['coordinate_location'].x\n",
    "    # state_units['lat'] = state_units['coordinate_location'].y\n",
    "    \n",
    "    print(\"PULLED AND PREPPED SOURCE DATA\", gov_unit_s3_path)\n",
    "\n",
    "    for index, row in state_units.iterrows():\n",
    "        print(\"PROCESSING CLAIMS AND ADDING:\", row.gnis_name)\n",
    "        # Set county fips code\n",
    "        claim_county_fips = ExternalID(\n",
    "            prop_nr=geokb_props['FIPS 6-4'],\n",
    "            value=row.stco_fipscode,\n",
    "            references=[[ref_source]]\n",
    "        )\n",
    "        \n",
    "        # Set GNIS code\n",
    "        claim_county_gnis = ExternalID(\n",
    "            prop_nr=geokb_props['GNIS ID'],\n",
    "            value=row.gnis_id,\n",
    "            references=[[ref_source]]\n",
    "        )\n",
    "        \n",
    "        # Set coordinate location\n",
    "        # claim_location = GlobeCoordinate(\n",
    "        #     prop_nr=geokb_props['coordinate location'],\n",
    "        #     latitude=row.lat,\n",
    "        #     longitude=row.lon,\n",
    "        #     references=[[ref_source]]\n",
    "        # )\n",
    "        \n",
    "        # Send it\n",
    "        add_item(\n",
    "            label=row.gnis_name, # I prefer this form for the context\n",
    "            description=f\"a county in {st['itemLabel']}\",\n",
    "            aliases=row.county_name,\n",
    "            claims=[\n",
    "                claim_instance_of,\n",
    "                claim_county_in_state,\n",
    "                claim_county_fips,\n",
    "                claim_county_gnis\n",
    "            ]\n",
    "        )\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98c70a54-14dc-48f4-ac61-e3deeaab95e8",
   "metadata": {},
   "source": [
    "### Fixing a mistake\n",
    "\n",
    "I messed up when I ran this yesterday and didn't include the claim_location. So, I need to run a different process to update items with coordinate location. This also points out how this kind of process really needs to be developed. For reference sources like this in the GeoKB, we need to be able to run something periodically based on the type of information and frequency of change. We need to be able to both establish a baseline and come back to improve on that baseline over time. I'm working through that more in some of the other notebooks so far.\n",
    "\n",
    "Here I'm going to start from the perspective of what's already in the GeoKB and go back to my source material from the TNM staged data to get county geometry, generate centroid point coordinates, and then send it to the existing items as a new claim."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "33a52e11-2a36-46ab-b026-3946a50a9876",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>county</th>\n",
       "      <th>countyLabel</th>\n",
       "      <th>state</th>\n",
       "      <th>stateLabel</th>\n",
       "      <th>fipps</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://geokb.wikibase.cloud/entity/Q482</td>\n",
       "      <td>Missaukee County</td>\n",
       "      <td>https://geokb.wikibase.cloud/entity/Q230</td>\n",
       "      <td>Michigan</td>\n",
       "      <td>26113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://geokb.wikibase.cloud/entity/Q483</td>\n",
       "      <td>Delta County</td>\n",
       "      <td>https://geokb.wikibase.cloud/entity/Q230</td>\n",
       "      <td>Michigan</td>\n",
       "      <td>26041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://geokb.wikibase.cloud/entity/Q484</td>\n",
       "      <td>Van Buren County</td>\n",
       "      <td>https://geokb.wikibase.cloud/entity/Q230</td>\n",
       "      <td>Michigan</td>\n",
       "      <td>26159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://geokb.wikibase.cloud/entity/Q485</td>\n",
       "      <td>Berrien County</td>\n",
       "      <td>https://geokb.wikibase.cloud/entity/Q230</td>\n",
       "      <td>Michigan</td>\n",
       "      <td>26021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://geokb.wikibase.cloud/entity/Q486</td>\n",
       "      <td>Gladwin County</td>\n",
       "      <td>https://geokb.wikibase.cloud/entity/Q230</td>\n",
       "      <td>Michigan</td>\n",
       "      <td>26051</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     county       countyLabel  \\\n",
       "0  https://geokb.wikibase.cloud/entity/Q482  Missaukee County   \n",
       "1  https://geokb.wikibase.cloud/entity/Q483      Delta County   \n",
       "2  https://geokb.wikibase.cloud/entity/Q484  Van Buren County   \n",
       "3  https://geokb.wikibase.cloud/entity/Q485    Berrien County   \n",
       "4  https://geokb.wikibase.cloud/entity/Q486    Gladwin County   \n",
       "\n",
       "                                      state stateLabel  fipps  \n",
       "0  https://geokb.wikibase.cloud/entity/Q230   Michigan  26113  \n",
       "1  https://geokb.wikibase.cloud/entity/Q230   Michigan  26041  \n",
       "2  https://geokb.wikibase.cloud/entity/Q230   Michigan  26159  \n",
       "3  https://geokb.wikibase.cloud/entity/Q230   Michigan  26021  \n",
       "4  https://geokb.wikibase.cloud/entity/Q230   Michigan  26051  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "geokb_county_query = \"\"\"\n",
    "PREFIX wd: <%(wb_domain)s/entity/>\n",
    "PREFIX wdt: <%(wb_domain)s/prop/direct/>\n",
    "\n",
    "SELECT ?county ?countyLabel ?state ?stateLabel ?fipps\n",
    "WHERE { \n",
    "    ?county  wdt:P1  wd:Q481 . \n",
    "    ?county wdt:P11 ?state .\n",
    "    OPTIONAL {\n",
    "      ?county wdt:P22 ?fipps .\n",
    "    }\n",
    "    SERVICE wikibase:label { bd:serviceParam  wikibase:language  \"en\" . } \n",
    "}\n",
    "\"\"\" % {'wb_domain': os.environ['WC_WIKIBASE_URL']}\n",
    "\n",
    "geokb_counties = sparql_query(\n",
    "    endpoint=os.environ['WC_SPARQL_ENDPOINT_URL'],\n",
    "    query=geokb_county_query,\n",
    "    output='dataframe'\n",
    ")\n",
    "geokb_counties.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2414f5f-8ad0-4c6b-98dd-5eeade628338",
   "metadata": {},
   "source": [
    "Now I have a choice, I can pull all the data I need to work with from the prd-tnm bucket, run through and get everything prepped, and then send it to the GeoKB, or I can pull it state-by-state like I did above. I'll see how the former works.\n",
    "\n",
    "This would be a great place to work up a parallel process to simply grab each source file, process to get what we want, and send to an accumulator. I took a quick crack at that approach but I need to brush up on Dask and S3 to figure some stuff out that I'm doing wrong. In the meantime, the data prep process is really fast."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a6e46853-56c1-4491-96b2-6385068c55ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 33.1 s, sys: 7.56 s, total: 40.7 s\n",
      "Wall time: 1min 24s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "source_files = []\n",
    "for state_name in geokb_counties.stateLabel.unique():\n",
    "    st = state_name.replace(' ', '_')\n",
    "    gov_unit_s3_path = next((i for i in tnm_state_gpkg if st in i), None)\n",
    "    if gov_unit_s3_path is not None:\n",
    "        source_files.append(get_unit_geo(gov_unit_s3_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "20f64a5b-1321-4e24-bf17-1adb9d27ed90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stco_fipscode</th>\n",
       "      <th>gnis_name</th>\n",
       "      <th>lon</th>\n",
       "      <th>lat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>26113</td>\n",
       "      <td>Missaukee County</td>\n",
       "      <td>-85.094682</td>\n",
       "      <td>44.337320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>26041</td>\n",
       "      <td>Delta County</td>\n",
       "      <td>-86.870597</td>\n",
       "      <td>45.791636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>26159</td>\n",
       "      <td>Van Buren County</td>\n",
       "      <td>-86.306415</td>\n",
       "      <td>42.285106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>26021</td>\n",
       "      <td>Berrien County</td>\n",
       "      <td>-86.685421</td>\n",
       "      <td>41.995778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>26051</td>\n",
       "      <td>Gladwin County</td>\n",
       "      <td>-84.388246</td>\n",
       "      <td>43.990674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>26063</td>\n",
       "      <td>Huron County</td>\n",
       "      <td>-82.855508</td>\n",
       "      <td>43.910068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>26121</td>\n",
       "      <td>Muskegon County</td>\n",
       "      <td>-86.535234</td>\n",
       "      <td>43.289930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>26035</td>\n",
       "      <td>Clare County</td>\n",
       "      <td>-84.847861</td>\n",
       "      <td>43.987892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>26111</td>\n",
       "      <td>Midland County</td>\n",
       "      <td>-84.388109</td>\n",
       "      <td>43.646857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>26015</td>\n",
       "      <td>Barry County</td>\n",
       "      <td>-85.308968</td>\n",
       "      <td>42.595028</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  stco_fipscode         gnis_name        lon        lat\n",
       "0         26113  Missaukee County -85.094682  44.337320\n",
       "1         26041      Delta County -86.870597  45.791636\n",
       "2         26159  Van Buren County -86.306415  42.285106\n",
       "3         26021    Berrien County -86.685421  41.995778\n",
       "4         26051    Gladwin County -84.388246  43.990674\n",
       "5         26063      Huron County -82.855508  43.910068\n",
       "6         26121   Muskegon County -86.535234  43.289930\n",
       "7         26035      Clare County -84.847861  43.987892\n",
       "8         26111    Midland County -84.388109  43.646857\n",
       "9         26015      Barry County -85.308968  42.595028"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_unit_coords = pd.concat(source_files)\n",
    "df_unit_coords.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "cd236adc-df35-4bff-928f-bbb6982ba083",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_geokb_county_coords = pd.merge(\n",
    "    left=geokb_counties,\n",
    "    right=df_unit_coords,\n",
    "    how=\"left\",\n",
    "    left_on=\"fipps\",\n",
    "    right_on=\"stco_fipscode\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "780c4401-0a55-458e-95c0-a1bea0f23ed5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Service unavailable (HTTP Code 502). Sleeping for 60 seconds.\n",
      "Service unavailable (HTTP Code 502). Sleeping for 60 seconds.\n",
      "Service unavailable (HTTP Code 502). Sleeping for 60 seconds.\n",
      "Service unavailable (HTTP Code 502). Sleeping for 60 seconds.\n",
      "Service unavailable (HTTP Code 502). Sleeping for 60 seconds.\n",
      "Service unavailable (HTTP Code 502). Sleeping for 60 seconds.\n"
     ]
    }
   ],
   "source": [
    "for index, row in df_geokb_county_coords.iterrows():\n",
    "    # Get source data path so we can build a reference\n",
    "    gov_unit_s3_path = next((i for i in tnm_state_gpkg if row.stateLabel.replace(' ', '_') in i), None)\n",
    "    \n",
    "    # Set up an http reference\n",
    "    http_ref = gov_unit_s3_path.replace('s3://prd-tnm/', 'https://prd-tnm.s3.amazonaws.com/')\n",
    "    \n",
    "    # Set up reference source to add to claims\n",
    "    ref_source = URL(\n",
    "        prop_nr=geokb_props['reference url'],\n",
    "        value=http_ref\n",
    "    )\n",
    "    \n",
    "    # Build coordinate location claim\n",
    "    claim_location = GlobeCoordinate(\n",
    "        prop_nr=geokb_props['coordinate location'],\n",
    "        latitude=row.lat,\n",
    "        longitude=row.lon,\n",
    "        references=[[ref_source]]\n",
    "    )\n",
    "    \n",
    "    # Get the county item\n",
    "    item = wbi.item.get(row.county.split(\"/\")[-1])\n",
    "    \n",
    "    # Add the claim\n",
    "    item.add_claims(claim_location)\n",
    "    \n",
    "    item.write()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22376152-7716-43c9-ad24-2b5bfd993786",
   "metadata": {},
   "source": [
    "On the processing front, my big time sink right now is on commitments to Wikibase. This should go faster than it is. Wikibase (and all the Wikiverse stuff) is awesome in that it is a big exciting open source project that has lots of activity and interest. That's great, but it also means that big group has come up with a whole diversity of approaches and supporting software. Some of that works really well in some circumstances but not in others. Even here, I've settled into using WikbaseIntegrator as my foundation because I ran into issues with pyWikibot. Jonathan Oliveros with Xentity ran into issues with WBI and is using pyWikibot. They are very different in approach and syntax to doing the same work.\n",
    "\n",
    "I think there's already some built out capacity for pushing millions of things in short order into Wikibase I need to research before trying to simply parallelize what I've got here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2baa905d-349d-43e7-b3ce-578a0e868efe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:geokb]",
   "language": "python",
   "name": "conda-env-geokb-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
